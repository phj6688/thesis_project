{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "def load_glove_embeddings(path):\n",
    "    word2vec_dict = {}            \n",
    "    with open(path, 'r', encoding='utf-8') as file:\n",
    "        for line in file:\n",
    "            try:\n",
    "                values = line.split()\n",
    "                word = values[0]\n",
    "                vector = np.asarray(values[1:], dtype='float32')\n",
    "                word2vec_dict[word] = vector\n",
    "            except ValueError:                \n",
    "                continue    \n",
    "    return word2vec_dict\n",
    "\n",
    "path = \"glove.840B.300d.txt\"\n",
    "word2vec = load_glove_embeddings(path)\n",
    "print(len(word2vec))\n",
    "\n",
    "\n",
    "import pickle\n",
    "\n",
    "with open('w2v.pkl', 'wb') as f:\n",
    "    pickle.dump(word2vec, f)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## --- process the fraction of datasets ---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "namelist = ['cr', 'trec', 'agnews', 'pc', 'yelp', 'kaggle_med', 'cardio', 'bbc', 'sst2','subj']\n",
    "for name in namelist:\n",
    "    df = pd.read_csv(f'data/original/{name}/train.csv')\n",
    "    df = df.sample(frac=0.5, random_state=100)\n",
    "    df.to_csv(f'data/original/{name}/train_50.csv', index=False)\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "torch.cuda.is_available()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## --- preprocess the data ---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data and remove all rows with nan or empty string or space or NONE or None or none or NaN or nan or NaT or nat or N/A or n/a or NULL or null or Null or nil or NIL or Nil or na or NA or n.a. or N.A. or n.a or N.a or N.A or n.A or n.A. or N.a. or N.A. or n.A. or n.A. or N.A. or n.a. or N.a\n",
    "# and print rows that removed\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "\n",
    "def clean(path):\n",
    "    df = pd.read_csv(path)\n",
    "    invalid_values = ['', ' ', 'NONE', 'None', 'none', 'NaN', 'nan', 'NaT', 'nat', 'N/A', 'n/a',\n",
    "                        'NULL', 'null', 'Null', 'nil', 'NIL', 'Nil', 'na', 'NA', 'n.a.', 'N.A.', 'n.a', 'N.a', 'N.A',\n",
    "                          'n.A', 'n.A.', 'N.a.', 'N.A.', 'n.A.', 'n.A.', 'N.A.', 'n.a.', 'N.a']\n",
    "    for text in df['text']:\n",
    "        if text in invalid_values and len(text) < 4:\n",
    "            # delete the row\n",
    "\n",
    "            # reset index and save to csv\n",
    "\n",
    "            \n",
    "            return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "namelist = ['cr', 'trec', 'agnews', 'pc', 'yelp', 'kaggle_med', 'cardio', 'bbc', 'sst2','subj']\n",
    "for name in namelist:\n",
    "    clean(f'data/original/{name}/train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "\n",
    "def clean(path):\n",
    "    df = pd.read_csv(path)\n",
    "    invalid_values = ['', ' ', 'NONE', 'None', 'none', 'NaN', 'nan', 'NaT', 'nat', 'N/A', 'n/a',\n",
    "                        'NULL', 'null', 'Null', 'nil', 'NIL', 'Nil', 'na', 'NA', 'n.a.', 'N.A.', 'n.a', 'N.a', 'N.A',\n",
    "                          'n.A', 'n.A.', 'N.a.', 'N.A.', 'n.A.', 'n.A.', 'N.A.', 'n.a.', 'N.a']\n",
    "    \n",
    "    invalid_rows = df[df['text'].apply(lambda x: x in invalid_values and len(x) < 4) | df['class'].apply(lambda x: x in invalid_values and len(x) < 4)]\n",
    "\n",
    "    # Print the removed rows\n",
    "    print(\"Removed rows:\")\n",
    "    print(invalid_rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "train_path = 'data/original/pubmed/train.csv'\n",
    "test_path = 'data/original/pubmed/test.csv'\n",
    "\n",
    "train_df = pd.read_csv(train_path)\n",
    "test_df = pd.read_csv(test_path)\n",
    "train_df['class'] = train_df['class'].map({'OBJECTIVE': 0, 'METHODS': 1, 'RESULTS': 2, 'CONCLUSIONS': 3, 'BACKGROUND': 4})\n",
    "test_df['class'] = test_df['class'].map({'OBJECTIVE': 0, 'METHODS': 1, 'RESULTS': 2, 'CONCLUSIONS': 3, 'BACKGROUND': 4})\n",
    "train_df.to_csv(train_path, index=False)\n",
    "test_df.to_csv(test_path, index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "for i in ['10', '20', '50']:\n",
    "    train_path = f'data/original/pubmed/train_{i}.csv'\n",
    "    df = pd.read_csv(train_path)\n",
    "    df['class'] = df['class'].map({'OBJECTIVE': 0, 'METHODS': 1, 'RESULTS': 2, 'CONCLUSIONS': 3, 'BACKGROUND': 4})\n",
    "    df.to_csv(train_path, index=False)\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## exploring the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_dict = {}\n",
    "path = 'results/original'\n",
    "model_list = ['bert', 'lstm','cnn']\n",
    "dataset_list = ['cr', 'trec', 'agnews', 'pc', 'yelp', 'kaggle_med', 'cardio', 'bbc', 'sst2','subj', 'pubmed']\n",
    "percentage_list = ['10_percent', '20_percent', '50_percent','full']\n",
    "numbers = ['10', '20', '50', 'full']\n",
    "\n",
    "for number, percentage in zip(numbers, percentage_list):\n",
    "    for model in model_list:\n",
    "        for dataset in dataset_list:\n",
    "            try:\n",
    "                new_dict[f'{model}_{dataset}_{percentage}'] = []\n",
    "                with open(f'{path}/{model}/{percentage}/{dataset}_{number}_results.txt', 'r') as f:\n",
    "                    for line in f:\n",
    "                        new_dict[f'{model}_{dataset}_{percentage}'].append(line.strip())    \n",
    "            except Exception as e:\n",
    "                if dataset != 'kaggle_med':\n",
    "                    print(f\"Error occurred: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_dict"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## exploring the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import pandas as pd\n",
    "\n",
    "new_dict = {}\n",
    "path = 'results/original'\n",
    "model_list = ['bert', 'lstm','cnn'] # 3 models\n",
    "dataset_list = ['cr', 'trec', 'agnews', 'pc', 'yelp', 'cardio', 'bbc', 'sst2','subj', 'pubmed'] # 10 datasets\n",
    "percentage_list = ['10_percent', '20_percent', '50_percent','full'] # 4 percentages\n",
    "numbers = ['10', '20', '50', 'full']\n",
    "\n",
    "for number, percentage in zip(numbers, percentage_list):\n",
    "    for model in model_list:\n",
    "        for dataset in dataset_list:\n",
    "            try:\n",
    "                new_dict[f'{model}_{dataset}_{percentage}'] = []\n",
    "                with open(f'{path}/{model}/{percentage}/{dataset}_{number}_results.txt', 'r') as f:\n",
    "                    for line in f:\n",
    "                        new_dict[f'{model}_{dataset}_{percentage}'].append(line.strip())    \n",
    "            except Exception as e:\n",
    "                if dataset != 'kaggle_med':\n",
    "                    print(f\"Error occurred: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame.from_dict(new_dict, orient='index')\n",
    "# create empty columns\n",
    "df['f1_score'] = None\n",
    "df['accuracy'] = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for index, row in df.iterrows():\n",
    "    for item in row:\n",
    "        if item is not None:\n",
    "            metric, value = item.split(\":\")\n",
    "            if metric.strip() in ['f1', 'f1_score']:\n",
    "                df.at[index, 'f1_score'] = float(value)\n",
    "            elif metric.strip() in ['acc', 'accuracy']:\n",
    "                df.at[index, 'accuracy'] = float(value)\n",
    "\n",
    "# keep only relevant columns\n",
    "df = df[['f1_score', 'accuracy']]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## creating datasets from 4 examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "aug_path = 'data/augmented/agnews/meth_eda_pctwts_0.5_example_4.csv'\n",
    "org_path = 'data/original/agnews/train.csv'\n",
    "df_aug = pd.read_csv(aug_path)\n",
    "df_org = pd.read_csv(org_path)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_aug[\"org\"] = df_aug[\"text\"].isin(df_org[\"text\"])\n",
    "df_aug['first_aug'] = df_aug['text'].shift(-1)\n",
    "df_aug['first_aug'] = df_aug['first_aug'].where(df_aug['first_aug'] != df_aug['text'], None)\n",
    "df_aug['second_aug'] = df_aug['text'].shift(-2)\n",
    "df_aug['second_aug'] = df_aug['second_aug'].where(df_aug['second_aug'] != df_aug['text'], None)\n",
    "na_indices = df_aug[df_aug['first_aug'].isna() | df_aug['second_aug'].isna()].index\n",
    "df_aug = df_aug.drop(na_indices)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Selecting rows where 'org' is True and only keeping 'class', 'text', 'first_aug', and 'second_aug' columns\n",
    "df_result = df_aug[df_aug['org'] == True][['class', 'text', 'first_aug', 'second_aug']]\n",
    "\n",
    "# Remove rows where 'second_aug' is in the original text\n",
    "# Remove rows where 'first_aug' is in the original text\n",
    "\n",
    "df_result = df_result[~df_result['first_aug'].isin(df_aug[df_aug['org'] == True]['text'])]\n",
    "df_result = df_result[~df_result['second_aug'].isin(df_aug[df_aug['org'] == True]['text'])]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_first_aug = df_result[['class', 'first_aug']].copy()\n",
    "df_first_aug.rename(columns={'first_aug': 'text'}, inplace=True)\n",
    "\n",
    "df_second_aug = df_result[['class', 'second_aug']].copy()\n",
    "df_second_aug.rename(columns={'second_aug': 'text'}, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_result['aug_number'] = 'original'\n",
    "df_first_aug['aug_number'] = 'first_aug'\n",
    "df_second_aug['aug_number'] = 'second_aug'\n",
    "\n",
    "df_all = pd.concat([df_result, df_first_aug, df_second_aug])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all.sort_index(inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_one_example = df_all[df_all['aug_number'].isin(['original', 'first_aug'])]\n",
    "df_two_examples = df_all[df_all['aug_number'].isin(['original', 'first_aug', 'second_aug'])]\n",
    "\n",
    "df_one_example = df_one_example[['class', 'text']]\n",
    "df_two_examples = df_two_examples[['class', 'text']]\n",
    "\n",
    "df_one_example.to_csv('data/augmented/agnews/meth_eda_pctwts_0.5_example_1.csv', index=False)\n",
    "df_two_examples.to_csv('data/augmented/agnews/meth_eda_pctwts_0.5_example_2.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>class</th>\n",
       "      <th>text</th>\n",
       "      <th>first_aug</th>\n",
       "      <th>second_aug</th>\n",
       "      <th>aug_number</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>NEW YORK (Reuters) - U.S. stocks recovered fr...</td>\n",
       "      <td>(Reuters) -.. stocks from earlier  losses ear...</td>\n",
       "      <td>NEW YORK (Reuters) - U.S. stocks recovered fr...</td>\n",
       "      <td>original</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>3</td>\n",
       "      <td>CHICAGO (Reuters) - The twin burdens of soari...</td>\n",
       "      <td>CHICAGO (twin) - U four the quarter soaring b...</td>\n",
       "      <td>CHICAGO (Reuters) - The couple essence of sur...</td>\n",
       "      <td>original</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>2</td>\n",
       "      <td>(CP) - The NHL all-star game hasn #39;t been c...</td>\n",
       "      <td>(adept CP) - ixl The NHL all-star game hasn #3...</td>\n",
       "      <td>(CP) - joined NHL to game cancelled #York;t be...</td>\n",
       "      <td>original</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>3</td>\n",
       "      <td>WASHINGTON (CBS.MW) -- New rules governing ove...</td>\n",
       "      <td>kicked (politically.MW) -- New debate governin...</td>\n",
       "      <td>(CBS.MW) -- New governing overtime in, spurrin...</td>\n",
       "      <td>original</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>2</td>\n",
       "      <td>DENVER (Ticker) -- Jake Plummer more than made...</td>\n",
       "      <td>DENVER (Ticker) -- Jake Plummer more than made...</td>\n",
       "      <td>DENVER (Ticker) -- Jake Plummer bronco more de...</td>\n",
       "      <td>original</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>599965</th>\n",
       "      <td>4</td>\n",
       "      <td>One of the most respected engineering gateways...</td>\n",
       "      <td>One technical the four hundreds engineering ga...</td>\n",
       "      <td>ane of the most esteem mastermind gateways on ...</td>\n",
       "      <td>original</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>599970</th>\n",
       "      <td>3</td>\n",
       "      <td>PORTLAND, Maine (Reuters) - Of the more than ...</td>\n",
       "      <td>Portland, ME (Reuters) - Of the more than oct...</td>\n",
       "      <td>downright, 8 (it's) - Of the more to of,000 f...</td>\n",
       "      <td>original</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>599975</th>\n",
       "      <td>1</td>\n",
       "      <td>A Saudi security officer is killed during a sh...</td>\n",
       "      <td>Saudi security killed during a shootout north ...</td>\n",
       "      <td>adenine Saudi-Arabian protection officer is ki...</td>\n",
       "      <td>original</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>599980</th>\n",
       "      <td>1</td>\n",
       "      <td>Yasser Arafat, long-time leader of the Palesti...</td>\n",
       "      <td>after Arafat, the leader of falling Palestinia...</td>\n",
       "      <td>Yasser Arafat, long-time leader of the Palesti...</td>\n",
       "      <td>original</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>599985</th>\n",
       "      <td>1</td>\n",
       "      <td>The government and the Moro Islamic Liberation...</td>\n",
       "      <td>The governing and the Moro Muslim sacking face...</td>\n",
       "      <td>The regime government and the Moro authorities...</td>\n",
       "      <td>original</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>119996 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        class                                               text  \\\n",
       "0           3   NEW YORK (Reuters) - U.S. stocks recovered fr...   \n",
       "5           3   CHICAGO (Reuters) - The twin burdens of soari...   \n",
       "10          2  (CP) - The NHL all-star game hasn #39;t been c...   \n",
       "15          3  WASHINGTON (CBS.MW) -- New rules governing ove...   \n",
       "20          2  DENVER (Ticker) -- Jake Plummer more than made...   \n",
       "...       ...                                                ...   \n",
       "599965      4  One of the most respected engineering gateways...   \n",
       "599970      3   PORTLAND, Maine (Reuters) - Of the more than ...   \n",
       "599975      1  A Saudi security officer is killed during a sh...   \n",
       "599980      1  Yasser Arafat, long-time leader of the Palesti...   \n",
       "599985      1  The government and the Moro Islamic Liberation...   \n",
       "\n",
       "                                                first_aug  \\\n",
       "0        (Reuters) -.. stocks from earlier  losses ear...   \n",
       "5        CHICAGO (twin) - U four the quarter soaring b...   \n",
       "10      (adept CP) - ixl The NHL all-star game hasn #3...   \n",
       "15      kicked (politically.MW) -- New debate governin...   \n",
       "20      DENVER (Ticker) -- Jake Plummer more than made...   \n",
       "...                                                   ...   \n",
       "599965  One technical the four hundreds engineering ga...   \n",
       "599970   Portland, ME (Reuters) - Of the more than oct...   \n",
       "599975  Saudi security killed during a shootout north ...   \n",
       "599980  after Arafat, the leader of falling Palestinia...   \n",
       "599985  The governing and the Moro Muslim sacking face...   \n",
       "\n",
       "                                               second_aug aug_number  \n",
       "0        NEW YORK (Reuters) - U.S. stocks recovered fr...   original  \n",
       "5        CHICAGO (Reuters) - The couple essence of sur...   original  \n",
       "10      (CP) - joined NHL to game cancelled #York;t be...   original  \n",
       "15      (CBS.MW) -- New governing overtime in, spurrin...   original  \n",
       "20      DENVER (Ticker) -- Jake Plummer bronco more de...   original  \n",
       "...                                                   ...        ...  \n",
       "599965  ane of the most esteem mastermind gateways on ...   original  \n",
       "599970   downright, 8 (it's) - Of the more to of,000 f...   original  \n",
       "599975  adenine Saudi-Arabian protection officer is ki...   original  \n",
       "599980  Yasser Arafat, long-time leader of the Palesti...   original  \n",
       "599985  The regime government and the Moro authorities...   original  \n",
       "\n",
       "[119996 rows x 5 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_first_aug"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_second_aug"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all.sort_index(inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>class</th>\n",
       "      <th>text</th>\n",
       "      <th>first_aug</th>\n",
       "      <th>second_aug</th>\n",
       "      <th>aug_number</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>NEW YORK (Reuters) - U.S. stocks recovered fr...</td>\n",
       "      <td>(Reuters) -.. stocks from earlier  losses ear...</td>\n",
       "      <td>NEW YORK (Reuters) - U.S. stocks recovered fr...</td>\n",
       "      <td>original</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>NEW YORK (Reuters) - U.S. stocks recovered fr...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>second_aug</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>(Reuters) -.. stocks from earlier  losses ear...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>first_aug</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>3</td>\n",
       "      <td>CHICAGO (Reuters) - The twin burdens of soari...</td>\n",
       "      <td>CHICAGO (twin) - U four the quarter soaring b...</td>\n",
       "      <td>CHICAGO (Reuters) - The couple essence of sur...</td>\n",
       "      <td>original</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>3</td>\n",
       "      <td>CHICAGO (Reuters) - The couple essence of sur...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>second_aug</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>599980</th>\n",
       "      <td>1</td>\n",
       "      <td>Yasser Arafat, long-time leader of the Palesti...</td>\n",
       "      <td>after Arafat, the leader of falling Palestinia...</td>\n",
       "      <td>Yasser Arafat, long-time leader of the Palesti...</td>\n",
       "      <td>original</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>599980</th>\n",
       "      <td>1</td>\n",
       "      <td>after Arafat, the leader of falling Palestinia...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>first_aug</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>599985</th>\n",
       "      <td>1</td>\n",
       "      <td>The governing and the Moro Muslim sacking face...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>first_aug</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>599985</th>\n",
       "      <td>1</td>\n",
       "      <td>The government and the Moro Islamic Liberation...</td>\n",
       "      <td>The governing and the Moro Muslim sacking face...</td>\n",
       "      <td>The regime government and the Moro authorities...</td>\n",
       "      <td>original</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>599985</th>\n",
       "      <td>1</td>\n",
       "      <td>The regime government and the Moro authorities...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>second_aug</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>359988 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        class                                               text  \\\n",
       "0           3   NEW YORK (Reuters) - U.S. stocks recovered fr...   \n",
       "0           3   NEW YORK (Reuters) - U.S. stocks recovered fr...   \n",
       "0           3   (Reuters) -.. stocks from earlier  losses ear...   \n",
       "5           3   CHICAGO (Reuters) - The twin burdens of soari...   \n",
       "5           3   CHICAGO (Reuters) - The couple essence of sur...   \n",
       "...       ...                                                ...   \n",
       "599980      1  Yasser Arafat, long-time leader of the Palesti...   \n",
       "599980      1  after Arafat, the leader of falling Palestinia...   \n",
       "599985      1  The governing and the Moro Muslim sacking face...   \n",
       "599985      1  The government and the Moro Islamic Liberation...   \n",
       "599985      1  The regime government and the Moro authorities...   \n",
       "\n",
       "                                                first_aug  \\\n",
       "0        (Reuters) -.. stocks from earlier  losses ear...   \n",
       "0                                                     NaN   \n",
       "0                                                     NaN   \n",
       "5        CHICAGO (twin) - U four the quarter soaring b...   \n",
       "5                                                     NaN   \n",
       "...                                                   ...   \n",
       "599980  after Arafat, the leader of falling Palestinia...   \n",
       "599980                                                NaN   \n",
       "599985                                                NaN   \n",
       "599985  The governing and the Moro Muslim sacking face...   \n",
       "599985                                                NaN   \n",
       "\n",
       "                                               second_aug  aug_number  \n",
       "0        NEW YORK (Reuters) - U.S. stocks recovered fr...    original  \n",
       "0                                                     NaN  second_aug  \n",
       "0                                                     NaN   first_aug  \n",
       "5        CHICAGO (Reuters) - The couple essence of sur...    original  \n",
       "5                                                     NaN  second_aug  \n",
       "...                                                   ...         ...  \n",
       "599980  Yasser Arafat, long-time leader of the Palesti...    original  \n",
       "599980                                                NaN   first_aug  \n",
       "599985                                                NaN   first_aug  \n",
       "599985  The regime government and the Moro authorities...    original  \n",
       "599985                                                NaN  second_aug  \n",
       "\n",
       "[359988 rows x 5 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_two_examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "aug_path = 'data/augmented/{dataset_name}/meth_{method_name}_pctwts_0.5_example_4.csv'\n",
    "org_path = 'data/original/agnews/train.csv'\n",
    "df_aug = pd.read_csv(aug_path)\n",
    "df_org = pd.read_csv(org_path)\n",
    "\n",
    "df_aug[\"org\"] = df_aug[\"text\"].isin(df_org[\"text\"])\n",
    "df_aug['first_aug'] = df_aug['text'].shift(-1)\n",
    "df_aug['first_aug'] = df_aug['first_aug'].where(df_aug['first_aug'] != df_aug['text'], None)\n",
    "df_aug['second_aug'] = df_aug['text'].shift(-2)\n",
    "df_aug['second_aug'] = df_aug['second_aug'].where(df_aug['second_aug'] != df_aug['text'], None)\n",
    "na_indices = df_aug[df_aug['first_aug'].isna() | df_aug['second_aug'].isna()].index\n",
    "df_aug = df_aug.drop(na_indices)\n",
    "\n",
    "# Selecting rows where 'org' is True and only keeping 'class', 'text', 'first_aug', and 'second_aug' columns\n",
    "df_result = df_aug[df_aug['org'] == True][['class', 'text', 'first_aug', 'second_aug']]\n",
    "\n",
    "# Remove rows where 'second_aug' is in the original text\n",
    "# Remove rows where 'first_aug' is in the original text\n",
    "\n",
    "df_result = df_result[~df_result['first_aug'].isin(df_aug[df_aug['org'] == True]['text'])]\n",
    "df_result = df_result[~df_result['second_aug'].isin(df_aug[df_aug['org'] == True]['text'])]\n",
    "\n",
    "df_first_aug = df_result[['class', 'first_aug']].copy()\n",
    "df_first_aug.rename(columns={'first_aug': 'text'}, inplace=True)\n",
    "\n",
    "df_second_aug = df_result[['class', 'second_aug']].copy()\n",
    "df_second_aug.rename(columns={'second_aug': 'text'}, inplace=True)\n",
    "\n",
    "df_result['aug_number'] = 'original'\n",
    "df_first_aug['aug_number'] = 'first_aug'\n",
    "df_second_aug['aug_number'] = 'second_aug'\n",
    "\n",
    "df_all = pd.concat([df_result, df_first_aug, df_second_aug])\n",
    "\n",
    "df_all.sort_index(inplace=True)\n",
    "\n",
    "df_one_example = df_all[df_all['aug_number'].isin(['original', 'first_aug'])]\n",
    "df_two_examples = df_all[df_all['aug_number'].isin(['original', 'first_aug', 'second_aug'])]\n",
    "\n",
    "df_one_example = df_one_example[['class', 'text']]\n",
    "df_two_examples = df_two_examples[['class', 'text']]\n",
    "\n",
    "df_one_example.to_csv('data/augmented/agnews/meth_eda_pctwts_0.5_example_1.csv', index=False)\n",
    "df_two_examples.to_csv('data/augmented/agnews/meth_eda_pctwts_0.5_example_2.csv', index=False)\n",
    "\n",
    "\n",
    "def create_aug_df_from_4_example(dataset_name,method_name):\n",
    "    aug_path = f'data/augmented/{dataset_name}/meth_{method_name}_pctwts_0.5_example_4.csv'\n",
    "    org_path = f'data/original/{dataset_name}/train.csv'\n",
    "    df_aug = pd.read_csv(aug_path)\n",
    "    df_org = pd.read_csv(org_path)\n",
    "    df_aug[\"org\"] = df_aug[\"text\"].isin(df_org[\"text\"])\n",
    "    df_aug['first_aug'] = df_aug['text'].shift(-1)\n",
    "    df_aug['first_aug'] = df_aug['first_aug'].where(df_aug['first_aug'] != df_aug['text'], None)\n",
    "    df_aug['second_aug'] = df_aug['text'].shift(-2)\n",
    "    df_aug['second_aug'] = df_aug['second_aug'].where(df_aug['second_aug'] != df_aug['text'], None)\n",
    "    na_indices = df_aug[df_aug['first_aug'].isna() | df_aug['second_aug'].isna()].index\n",
    "    df_aug = df_aug.drop(na_indices)\n",
    "\n",
    "    # Selecting rows where 'org' is True and only keeping 'class', 'text', 'first_aug', and 'second_aug' columns\n",
    "    df_result = df_aug[df_aug['org'] == True][['class', 'text', 'first_aug', 'second_aug']]\n",
    "\n",
    "    # Remove rows where 'second_aug' is in the original text\n",
    "    # Remove rows where 'first_aug' is in the original text\n",
    "\n",
    "    df_result = df_result[~df_result['first_aug'].isin(df_aug[df_aug['org'] == True]['text'])]\n",
    "    df_result = df_result[~df_result['second_aug'].isin(df_aug[df_aug['org'] == True]['text'])]\n",
    "\n",
    "    df_first_aug = df_result[['class', 'first_aug']].copy()\n",
    "    df_first_aug.rename(columns={'first_aug': 'text'}, inplace=True)\n",
    "\n",
    "    df_second_aug = df_result[['class', 'second_aug']].copy()\n",
    "    df_second_aug.rename(columns={'second_aug': 'text'}, inplace=True)\n",
    "\n",
    "    df_result['aug_number'] = 'original'\n",
    "    df_first_aug['aug_number'] = 'first_aug'\n",
    "    df_second_aug['aug_number'] = 'second_aug'\n",
    "\n",
    "    df_all = pd.concat([df_result, df_first_aug, df_second_aug])\n",
    "\n",
    "    df_all.sort_index(inplace=True)\n",
    "\n",
    "    df_one_example = df_all[df_all['aug_number'].isin(['original', 'first_aug'])]\n",
    "    df_two_examples = df_all[df_all['aug_number'].isin(['original', 'first_aug', 'second_aug'])]\n",
    "\n",
    "    df_one_example = df_one_example[['class', 'text']]\n",
    "    df_two_examples = df_two_examples[['class', 'text']]\n",
    "\n",
    "    df_one_example.to_csv('data/augmented/{dataset_name}/meth_{method_name}_pctwts_0.5_example_1.csv', index=False)\n",
    "    df_two_examples.to_csv('data/augmented/{dataset_name}/meth_{method_name}_pctwts_0.5_example_2.csv', index=False)\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "def remove_na_augmentations(df_aug, df_org):\n",
    "    \"\"\"\n",
    "    This function identifies original and augmented texts and removes NA augmentations.\n",
    "    \n",
    "    Parameters:\n",
    "    - df_aug: DataFrame, the augmented data\n",
    "    - df_org: DataFrame, the original data\n",
    "\n",
    "    Returns:\n",
    "    - df_aug: DataFrame, the augmented data with NAs removed\n",
    "    \"\"\"\n",
    "    df_aug[\"org\"] = df_aug[\"text\"].isin(df_org[\"text\"])\n",
    "    df_aug['first_aug'] = df_aug['text'].shift(-1)\n",
    "    df_aug['first_aug'] = df_aug['first_aug'].where(df_aug['first_aug'] != df_aug['text'], None)\n",
    "    df_aug['second_aug'] = df_aug['text'].shift(-2)\n",
    "    df_aug['second_aug'] = df_aug['second_aug'].where(df_aug['second_aug'] != df_aug['text'], None)\n",
    "    na_indices = df_aug[df_aug['first_aug'].isna() | df_aug['second_aug'].isna()].index\n",
    "    df_aug = df_aug.drop(na_indices)\n",
    "\n",
    "    return df_aug\n",
    "\n",
    "\n",
    "def select_org_and_aug_cols(df_aug):\n",
    "    \"\"\"\n",
    "    This function selects relevant columns of original and augmented texts.\n",
    "\n",
    "    Parameters:\n",
    "    - df_aug: DataFrame, the augmented data\n",
    "\n",
    "    Returns:\n",
    "    - df_result: DataFrame, the selected columns from the data\n",
    "    \"\"\"\n",
    "    df_result = df_aug[df_aug['org'] == True][['class', 'text', 'first_aug', 'second_aug']]\n",
    "    return df_result\n",
    "\n",
    "\n",
    "def create_augmentations(df_result, df_aug):\n",
    "    \"\"\"\n",
    "    This function creates DataFrame of original and augmented texts.\n",
    "\n",
    "    Parameters:\n",
    "    - df_result: DataFrame, the selected columns from the data\n",
    "    - df_aug: DataFrame, the augmented data\n",
    "\n",
    "    Returns:\n",
    "    - df_one_example: DataFrame, one example of augmented data\n",
    "    - df_two_examples: DataFrame, two examples of augmented data\n",
    "    \"\"\"\n",
    "    df_result = df_result[~df_result['first_aug'].isin(df_aug[df_aug['org'] == True]['text'])]\n",
    "    df_result = df_result[~df_result['second_aug'].isin(df_aug[df_aug['org'] == True]['text'])]\n",
    "\n",
    "    df_first_aug = df_result[['class', 'first_aug']].copy()\n",
    "    df_first_aug.rename(columns={'first_aug': 'text'}, inplace=True)\n",
    "\n",
    "    df_second_aug = df_result[['class', 'second_aug']].copy()\n",
    "    df_second_aug.rename(columns={'second_aug': 'text'}, inplace=True)\n",
    "\n",
    "    df_result['aug_number'] = 'original'\n",
    "    df_first_aug['aug_number'] = 'first_aug'\n",
    "    df_second_aug['aug_number'] = 'second_aug'\n",
    "\n",
    "    df_all = pd.concat([df_result, df_first_aug, df_second_aug])\n",
    "\n",
    "    df_all.sort_index(inplace=True)\n",
    "\n",
    "    df_one_example = df_all[df_all['aug_number'].isin(['original', 'first_aug'])]\n",
    "    df_two_examples = df_all[df_all['aug_number'].isin(['original', 'first_aug', 'second_aug'])]\n",
    "\n",
    "    df_one_example = df_one_example[['class', 'text']]\n",
    "    df_two_examples = df_two_examples[['class', 'text']]\n",
    "\n",
    "    return df_one_example, df_two_examples\n",
    "\n",
    "\n",
    "def create_aug_df_from_4_example(dataset_name,method_name):\n",
    "    \"\"\"\n",
    "    This function creates a dataframe with one and two augmented versions from the original \n",
    "    and four augmentations.\n",
    "    \n",
    "    Parameters:\n",
    "    - dataset_name: str, name of the dataset\n",
    "    - method_name: str, name of the method used for data augmentation\n",
    "\n",
    "    Returns:\n",
    "    - None. The function writes the output to CSV files.\n",
    "    \"\"\"\n",
    "    aug_path = f'data/augmented/{dataset_name}/meth_{method_name}_pctwts_0.5_example_4.csv'\n",
    "    org_path = f'data/original/{dataset_name}/train.csv'\n",
    "    \n",
    "    df_aug = pd.read_csv(aug_path)\n",
    "    df_org = pd.read_csv(org_path)\n",
    "    \n",
    "    df_aug = remove_na_augmentations(df_aug, df_org)\n",
    "    df_result = select_org_and_aug_cols(df_aug)\n",
    "    \n",
    "    df_one_example, df_two_examples = create_augmentations(df_result, df_aug)\n",
    "    \n",
    "    df_one_example.to_csv(f'data/augmented/{dataset_name}/meth_{method_name}_pctwts_0.5_example_1.csv', index=False)\n",
    "    df_two_examples.to_csv(f'data/augmented/{dataset_name}/meth_{method_name}_pctwts_0.5_example_2.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_aug_df_from_4_example('yelp','checklist')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
