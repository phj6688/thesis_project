{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ==========================================================="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow.keras.backend as K\n",
    "import tensorflow.keras.layers as layers\n",
    "import tensorflow.keras.regularizers as regularizers\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.callbacks import TensorBoard\n",
    "import tensorflow_addons as tfa\n",
    "from datetime import datetime\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "import pickle\n",
    "import os\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = ''\n",
    "np.random.seed(100)\n",
    "import random\n",
    "random.seed(100)\n",
    "tf.random.set_seed(100)\n",
    "\n",
    "class CNN:\n",
    "    def __init__(self,dims,w2v_path,max_seq_len=20,batch_size=128,epochs=20):\n",
    "        self.dims = dims\n",
    "        self.max_seq_len = max_seq_len\n",
    "        self.batch_size = batch_size\n",
    "        self.epochs = epochs\n",
    "        with open(w2v_path, 'rb') as f:            \n",
    "            self.w2v = pickle.load(f)\n",
    "        self.model = None        \n",
    "        self.label_mapping = None\n",
    "        self.n_classes = None\n",
    "        self.history = None\n",
    "        self.metrics = None #[tf.keras.metrics.AUC(name='auc'), tfa.metrics.F1Score(self.n_classes, average='weighted', name='f1_score'), 'accuracy']\n",
    "        log_dir = f\"logs/fit/run_only_once\" + datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "        tensorboard_callback = TensorBoard(log_dir=log_dir, histogram_freq=1)\n",
    "        decay_rate = tf.keras.callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=5, verbose=1, mode='auto', min_delta=0.0001 ,min_lr=0.00001)\n",
    "        early_stopping = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=5, verbose=1, mode='auto', restore_best_weights=True)\n",
    "        self.callbacks = [tensorboard_callback, decay_rate, early_stopping]\n",
    "\n",
    "\n",
    "    def build_cnn(self):\n",
    "        if self.n_classes > 2:\n",
    "            loss = 'categorical_crossentropy'\n",
    "            activation = 'softmax'\n",
    "        else:\n",
    "            loss = 'binary_crossentropy'\n",
    "            activation = 'sigmoid'\n",
    "\n",
    "        input_layer = layers.Input(shape=(self.max_seq_len, 300))\n",
    "        conv1_1 = layers.Conv1D(128, 4, activation='relu', padding='same')(input_layer)\n",
    "        conv1_2 = layers.Conv1D(128, 5, activation='relu', padding='same')(conv1_1)\n",
    "        #conv1_3 = layers.Conv1D(128, 5, activation='relu', padding='same')(conv1_2)\n",
    "        conv_out = layers.Concatenate(axis=1)([conv1_1, conv1_2])\n",
    "\n",
    "        dropout_rate = 0.5\n",
    "        dropout_out1 = layers.Dropout(dropout_rate)(conv_out)\n",
    "\n",
    "        pool_out = layers.MaxPool1D(pool_size=self.max_seq_len, padding='valid')(dropout_out1)\n",
    "        flatten_out = layers.Flatten()(pool_out)\n",
    "        dropout_out2 = layers.Dropout(dropout_rate)(flatten_out)\n",
    "        dense_out = layers.Dense(self.n_classes, activation=activation, kernel_regularizer=regularizers.L2(0.001))(dropout_out2)\n",
    "        \n",
    "        self.metrics = [tf.keras.metrics.AUC(name='auc'), tfa.metrics.F1Score(self.n_classes, average='weighted', name='f1_score'), 'accuracy']\n",
    "        cnn_model = Model(inputs=input_layer, outputs=dense_out)\n",
    "        cnn_model.compile(optimizer='adam', loss=loss, metrics=self.metrics)\n",
    "        #cnn_model.summary()\n",
    "        self.model = cnn_model\n",
    "        \n",
    "    def insert_values(self,train_path,test_path):    \n",
    "        def insert(df):\n",
    "            \n",
    "            # initialize x self.and y matrices\n",
    "            num_lines = len(df)\n",
    "            self.n_classes = df['class'].nunique()          \n",
    "            x_matrix = np.zeros((num_lines, self.max_seq_len ,300))\n",
    "            y_matrix = np.zeros((num_lines, self.n_classes))\n",
    "\n",
    "\n",
    "            # insert values\n",
    "            for i, row in df.iterrows():\n",
    "                label = row[0]\n",
    "                sentence = row[1]\n",
    "                if isinstance(sentence, str):\n",
    "                    words = sentence.split()[:self.max_seq_len]\n",
    "                    for j, word in enumerate(words):\n",
    "                        if word in self.w2v:\n",
    "                            x_matrix[i, j, :] = self.w2v[word]\n",
    "                else:\n",
    "                    continue        \n",
    "                y_matrix[i,label] = 1.0    \n",
    "\n",
    "            return x_matrix,y_matrix\n",
    "        \n",
    "        train_df = pd.read_csv(train_path)\n",
    "        test_df = pd.read_csv(test_path)\n",
    "\n",
    "        self.n_classes = train_df['class'].nunique()        \n",
    "        unique_classes = train_df['class'].unique()\n",
    "        labels_map = dict(zip(unique_classes, range(self.n_classes)))\n",
    "\n",
    "        train_df['class'] = train_df['class'].map(labels_map)\n",
    "        test_df['class'] = test_df['class'].map(labels_map)\n",
    "\n",
    "        train_df, val_df = train_test_split(train_df, test_size=0.1, random_state=100)\n",
    "        print(f'Train size: {len(train_df)}\\nValidation size: {len(val_df)}\\nTest size: {len(test_df)}')\n",
    "\n",
    "        train_df = train_df.sample(frac=1).reset_index(drop=True)\n",
    "        test_df = test_df.sample(frac=1).reset_index(drop=True)\n",
    "        val_df = val_df.sample(frac=1).reset_index(drop=True)\n",
    "\n",
    "        train_x, train_y = insert(train_df)\n",
    "        test_x, test_y = insert(test_df)\n",
    "        val_x, val_y = insert(val_df)\n",
    "\n",
    "        return train_x, train_y, test_x, test_y, val_x, val_y, self.n_classes          \n",
    "\n",
    "    def fit(self,train_x, train_y,  val_x, val_y):\n",
    "        self.metrics = [tf.keras.metrics.AUC(name='auc'), tfa.metrics.F1Score(self.n_classes, average='weighted', name='f1_score'), 'accuracy']\n",
    "        self.build_cnn()  \n",
    "        self.history = self.model.fit(train_x, train_y, batch_size=self.batch_size, epochs=self.epochs, validation_data=(val_x, val_y), callbacks=self.callbacks)\n",
    "        return self.history\n",
    "    def evaluate(self,test_x, test_y):\n",
    "        return self.model.evaluate(test_x, test_y,return_dict=True)\n",
    "\n",
    "    def run_n_times(self,train_x, train_y, test_x, test_y, val_x, val_y, n=3):\n",
    "        hist_dict = {}\n",
    "        res_dict = {}\n",
    "        for i in range(n):\n",
    "            print(f'Run {i+1} of {n}')\n",
    "            hist_dict[i+1] = self.fit(train_x, train_y, val_x, val_y)\n",
    "            res_dict[i+1] = self.evaluate(test_x, test_y)\n",
    "            self.model.set_weights([np.zeros(w.shape) for w in self.model.get_weights()])\n",
    "            # self.fit(train_x, train_y, val_x, val_y)\n",
    "            # self.evaluate(test_x, test_y)\n",
    "        avg_dict = {metric: round(sum(values[metric] for values in res_dict.values()) / len(res_dict), 4)  for metric in res_dict[1].keys()}\n",
    "        return hist_dict, res_dict, avg_dict\n",
    "\n",
    "    # save the results and best model\n",
    "    def save_results(self, hist_dict, res_dict, avg_dict, model_name):\n",
    "        # save the results\n",
    "        with open(f'{model_name}_results.json', 'w') as f:\n",
    "            json.dump(res_dict, f)\n",
    "        with open(f'{model_name}_avg_results.json', 'w') as f:\n",
    "            json.dump(avg_dict, f)\n",
    "        # save the best model\n",
    "        self.model.save(model_name)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_path  = 'data/original/cr/train.csv'\n",
    "test_path   = 'data/original/cr/test.csv'\n",
    "w2v_path = 'w2v.pkl'\n",
    "max_seq_len = 32\n",
    "batch_size = 128\n",
    "epochs = 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = CNN(dims=300, max_seq_len=max_seq_len, batch_size=batch_size, epochs=epochs, w2v_path=w2v_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train size: 3660\n",
      "Validation size: 407\n",
      "Test size: 451\n"
     ]
    }
   ],
   "source": [
    "train_x, train_y, test_x, test_y, val_x, val_y, n_classes = model.insert_values(train_path,test_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run 1 of 3\n",
      "Epoch 1/30\n",
      "29/29 [==============================] - 5s 95ms/step - loss: 0.6960 - auc: 0.6833 - f1_score: 0.6430 - accuracy: 0.6730 - val_loss: 0.5441 - val_auc: 0.8483 - val_f1_score: 0.7486 - val_accuracy: 0.7666 - lr: 0.0010\n",
      "Epoch 2/30\n",
      "29/29 [==============================] - 2s 78ms/step - loss: 0.4984 - auc: 0.8374 - f1_score: 0.7628 - accuracy: 0.7694 - val_loss: 0.4635 - val_auc: 0.9036 - val_f1_score: 0.8299 - val_accuracy: 0.8305 - lr: 0.0010\n",
      "Epoch 3/30\n",
      "29/29 [==============================] - 2s 76ms/step - loss: 0.4249 - auc: 0.8871 - f1_score: 0.8049 - accuracy: 0.8071 - val_loss: 0.4254 - val_auc: 0.9188 - val_f1_score: 0.8425 - val_accuracy: 0.8428 - lr: 0.0010\n",
      "Epoch 4/30\n",
      "29/29 [==============================] - 2s 76ms/step - loss: 0.3733 - auc: 0.9156 - f1_score: 0.8373 - accuracy: 0.8380 - val_loss: 0.3946 - val_auc: 0.9288 - val_f1_score: 0.8519 - val_accuracy: 0.8526 - lr: 0.0010\n",
      "Epoch 5/30\n",
      "29/29 [==============================] - 2s 77ms/step - loss: 0.3248 - auc: 0.9387 - f1_score: 0.8679 - accuracy: 0.8686 - val_loss: 0.3745 - val_auc: 0.9308 - val_f1_score: 0.8538 - val_accuracy: 0.8550 - lr: 0.0010\n",
      "Epoch 6/30\n",
      "29/29 [==============================] - 2s 76ms/step - loss: 0.2876 - auc: 0.9525 - f1_score: 0.8873 - accuracy: 0.8874 - val_loss: 0.3742 - val_auc: 0.9252 - val_f1_score: 0.8442 - val_accuracy: 0.8477 - lr: 0.0010\n",
      "Epoch 7/30\n",
      "29/29 [==============================] - 2s 78ms/step - loss: 0.2372 - auc: 0.9706 - f1_score: 0.9149 - accuracy: 0.9153 - val_loss: 0.3588 - val_auc: 0.9272 - val_f1_score: 0.8407 - val_accuracy: 0.8428 - lr: 0.0010\n",
      "Epoch 8/30\n",
      "29/29 [==============================] - 2s 78ms/step - loss: 0.1778 - auc: 0.9852 - f1_score: 0.9417 - accuracy: 0.9418 - val_loss: 0.3513 - val_auc: 0.9271 - val_f1_score: 0.8348 - val_accuracy: 0.8378 - lr: 0.0010\n",
      "Epoch 9/30\n",
      "29/29 [==============================] - 2s 77ms/step - loss: 0.1297 - auc: 0.9940 - f1_score: 0.9644 - accuracy: 0.9645 - val_loss: 0.3405 - val_auc: 0.9301 - val_f1_score: 0.8439 - val_accuracy: 0.8452 - lr: 0.0010\n",
      "Epoch 10/30\n",
      "29/29 [==============================] - 2s 76ms/step - loss: 0.0938 - auc: 0.9971 - f1_score: 0.9760 - accuracy: 0.9760 - val_loss: 0.3437 - val_auc: 0.9286 - val_f1_score: 0.8564 - val_accuracy: 0.8575 - lr: 0.0010\n",
      "Epoch 11/30\n",
      "29/29 [==============================] - 2s 75ms/step - loss: 0.0690 - auc: 0.9987 - f1_score: 0.9896 - accuracy: 0.9896 - val_loss: 0.3595 - val_auc: 0.9250 - val_f1_score: 0.8428 - val_accuracy: 0.8452 - lr: 0.0010\n",
      "Epoch 12/30\n",
      "29/29 [==============================] - 2s 76ms/step - loss: 0.0496 - auc: 0.9997 - f1_score: 0.9932 - accuracy: 0.9932 - val_loss: 0.3625 - val_auc: 0.9236 - val_f1_score: 0.8486 - val_accuracy: 0.8477 - lr: 0.0010\n",
      "Epoch 13/30\n",
      "29/29 [==============================] - 2s 75ms/step - loss: 0.0476 - auc: 0.9995 - f1_score: 0.9929 - accuracy: 0.9929 - val_loss: 0.3747 - val_auc: 0.9220 - val_f1_score: 0.8340 - val_accuracy: 0.8354 - lr: 0.0010\n",
      "Epoch 14/30\n",
      "28/29 [===========================>..] - ETA: 0s - loss: 0.0347 - auc: 0.9999 - f1_score: 0.9947 - accuracy: 0.9947\n",
      "Epoch 14: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\n",
      "Restoring model weights from the end of the best epoch: 9.\n",
      "29/29 [==============================] - 2s 79ms/step - loss: 0.0345 - auc: 0.9999 - f1_score: 0.9948 - accuracy: 0.9948 - val_loss: 0.3635 - val_auc: 0.9275 - val_f1_score: 0.8447 - val_accuracy: 0.8452 - lr: 0.0010\n",
      "Epoch 14: early stopping\n",
      "15/15 [==============================] - 0s 9ms/step - loss: 0.3877 - auc: 0.9074 - f1_score: 0.8301 - accuracy: 0.8293\n",
      "Run 2 of 3\n",
      "Epoch 1/30\n",
      "29/29 [==============================] - 4s 91ms/step - loss: 0.6703 - auc: 0.6978 - f1_score: 0.6346 - accuracy: 0.6571 - val_loss: 0.5119 - val_auc: 0.8603 - val_f1_score: 0.7471 - val_accuracy: 0.7690 - lr: 0.0010\n",
      "Epoch 2/30\n",
      "29/29 [==============================] - 2s 75ms/step - loss: 0.4832 - auc: 0.8501 - f1_score: 0.7665 - accuracy: 0.7724 - val_loss: 0.4398 - val_auc: 0.9186 - val_f1_score: 0.8415 - val_accuracy: 0.8403 - lr: 0.0010\n",
      "Epoch 3/30\n",
      "29/29 [==============================] - 3s 114ms/step - loss: 0.4049 - auc: 0.8986 - f1_score: 0.8199 - accuracy: 0.8219 - val_loss: 0.4009 - val_auc: 0.9302 - val_f1_score: 0.8579 - val_accuracy: 0.8575 - lr: 0.0010\n",
      "Epoch 4/30\n",
      "29/29 [==============================] - 2s 78ms/step - loss: 0.3653 - auc: 0.9191 - f1_score: 0.8394 - accuracy: 0.8402 - val_loss: 0.3671 - val_auc: 0.9398 - val_f1_score: 0.8611 - val_accuracy: 0.8624 - lr: 0.0010\n",
      "Epoch 5/30\n",
      "29/29 [==============================] - 2s 78ms/step - loss: 0.3059 - auc: 0.9464 - f1_score: 0.8814 - accuracy: 0.8820 - val_loss: 0.3499 - val_auc: 0.9440 - val_f1_score: 0.8661 - val_accuracy: 0.8673 - lr: 0.0010\n",
      "Epoch 6/30\n",
      "29/29 [==============================] - 2s 79ms/step - loss: 0.2726 - auc: 0.9579 - f1_score: 0.8954 - accuracy: 0.8959 - val_loss: 0.3443 - val_auc: 0.9461 - val_f1_score: 0.8614 - val_accuracy: 0.8624 - lr: 0.0010\n",
      "Epoch 7/30\n",
      "29/29 [==============================] - 2s 76ms/step - loss: 0.2215 - auc: 0.9744 - f1_score: 0.9219 - accuracy: 0.9221 - val_loss: 0.3280 - val_auc: 0.9394 - val_f1_score: 0.8619 - val_accuracy: 0.8649 - lr: 0.0010\n",
      "Epoch 8/30\n",
      "29/29 [==============================] - 3s 91ms/step - loss: 0.1670 - auc: 0.9870 - f1_score: 0.9460 - accuracy: 0.9462 - val_loss: 0.3165 - val_auc: 0.9448 - val_f1_score: 0.8633 - val_accuracy: 0.8649 - lr: 0.0010\n",
      "Epoch 9/30\n",
      "29/29 [==============================] - 3s 94ms/step - loss: 0.1134 - auc: 0.9958 - f1_score: 0.9707 - accuracy: 0.9708 - val_loss: 0.3113 - val_auc: 0.9422 - val_f1_score: 0.8780 - val_accuracy: 0.8796 - lr: 0.0010\n",
      "Epoch 10/30\n",
      "29/29 [==============================] - 3s 98ms/step - loss: 0.0779 - auc: 0.9985 - f1_score: 0.9847 - accuracy: 0.9847 - val_loss: 0.3194 - val_auc: 0.9397 - val_f1_score: 0.8720 - val_accuracy: 0.8747 - lr: 0.0010\n",
      "Epoch 11/30\n",
      "29/29 [==============================] - 3s 97ms/step - loss: 0.0555 - auc: 0.9994 - f1_score: 0.9918 - accuracy: 0.9918 - val_loss: 0.3137 - val_auc: 0.9425 - val_f1_score: 0.8643 - val_accuracy: 0.8673 - lr: 0.0010\n",
      "Epoch 12/30\n",
      "29/29 [==============================] - 3s 97ms/step - loss: 0.0405 - auc: 0.9999 - f1_score: 0.9956 - accuracy: 0.9956 - val_loss: 0.3173 - val_auc: 0.9426 - val_f1_score: 0.8762 - val_accuracy: 0.8771 - lr: 0.0010\n",
      "Epoch 13/30\n",
      "29/29 [==============================] - 3s 95ms/step - loss: 0.0286 - auc: 0.9999 - f1_score: 0.9989 - accuracy: 0.9989 - val_loss: 0.3346 - val_auc: 0.9401 - val_f1_score: 0.8758 - val_accuracy: 0.8771 - lr: 0.0010\n",
      "Epoch 14/30\n",
      "29/29 [==============================] - ETA: 0s - loss: 0.0252 - auc: 0.9999 - f1_score: 0.9981 - accuracy: 0.9981\n",
      "Epoch 14: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\n",
      "Restoring model weights from the end of the best epoch: 9.\n",
      "29/29 [==============================] - 3s 98ms/step - loss: 0.0252 - auc: 0.9999 - f1_score: 0.9981 - accuracy: 0.9981 - val_loss: 0.3263 - val_auc: 0.9424 - val_f1_score: 0.8770 - val_accuracy: 0.8771 - lr: 0.0010\n",
      "Epoch 14: early stopping\n",
      "15/15 [==============================] - 0s 12ms/step - loss: 0.3787 - auc: 0.9125 - f1_score: 0.8380 - accuracy: 0.8381\n",
      "Run 3 of 3\n",
      "Epoch 1/30\n",
      "29/29 [==============================] - 4s 114ms/step - loss: 0.6924 - auc: 0.6782 - f1_score: 0.6236 - accuracy: 0.6475 - val_loss: 0.5467 - val_auc: 0.8105 - val_f1_score: 0.6448 - val_accuracy: 0.7027 - lr: 0.0010\n",
      "Epoch 2/30\n",
      "29/29 [==============================] - 3s 93ms/step - loss: 0.5073 - auc: 0.8305 - f1_score: 0.7529 - accuracy: 0.7607 - val_loss: 0.4631 - val_auc: 0.8969 - val_f1_score: 0.7971 - val_accuracy: 0.8010 - lr: 0.0010\n",
      "Epoch 3/30\n",
      "29/29 [==============================] - 3s 96ms/step - loss: 0.4249 - auc: 0.8869 - f1_score: 0.8089 - accuracy: 0.8107 - val_loss: 0.4311 - val_auc: 0.9117 - val_f1_score: 0.8484 - val_accuracy: 0.8477 - lr: 0.0010\n",
      "Epoch 4/30\n",
      "29/29 [==============================] - 3s 96ms/step - loss: 0.3730 - auc: 0.9160 - f1_score: 0.8426 - accuracy: 0.8432 - val_loss: 0.3943 - val_auc: 0.9253 - val_f1_score: 0.8573 - val_accuracy: 0.8575 - lr: 0.0010\n",
      "Epoch 5/30\n",
      "29/29 [==============================] - 4s 126ms/step - loss: 0.3293 - auc: 0.9362 - f1_score: 0.8635 - accuracy: 0.8639 - val_loss: 0.3772 - val_auc: 0.9304 - val_f1_score: 0.8594 - val_accuracy: 0.8600 - lr: 0.0010\n",
      "Epoch 6/30\n",
      "29/29 [==============================] - 4s 129ms/step - loss: 0.2978 - auc: 0.9485 - f1_score: 0.8768 - accuracy: 0.8770 - val_loss: 0.3759 - val_auc: 0.9230 - val_f1_score: 0.8445 - val_accuracy: 0.8477 - lr: 0.0010\n",
      "Epoch 7/30\n",
      "29/29 [==============================] - 3s 120ms/step - loss: 0.2460 - auc: 0.9679 - f1_score: 0.9091 - accuracy: 0.9096 - val_loss: 0.3558 - val_auc: 0.9328 - val_f1_score: 0.8626 - val_accuracy: 0.8624 - lr: 0.0010\n",
      "Epoch 8/30\n",
      "29/29 [==============================] - 4s 131ms/step - loss: 0.1908 - auc: 0.9819 - f1_score: 0.9353 - accuracy: 0.9355 - val_loss: 0.3473 - val_auc: 0.9291 - val_f1_score: 0.8551 - val_accuracy: 0.8575 - lr: 0.0010\n",
      "Epoch 9/30\n",
      "29/29 [==============================] - 4s 128ms/step - loss: 0.1494 - auc: 0.9905 - f1_score: 0.9579 - accuracy: 0.9579 - val_loss: 0.3322 - val_auc: 0.9344 - val_f1_score: 0.8663 - val_accuracy: 0.8673 - lr: 0.0010\n",
      "Epoch 10/30\n",
      "29/29 [==============================] - 4s 129ms/step - loss: 0.1072 - auc: 0.9960 - f1_score: 0.9713 - accuracy: 0.9713 - val_loss: 0.3378 - val_auc: 0.9318 - val_f1_score: 0.8635 - val_accuracy: 0.8649 - lr: 0.0010\n",
      "Epoch 11/30\n",
      "29/29 [==============================] - 4s 129ms/step - loss: 0.0758 - auc: 0.9989 - f1_score: 0.9852 - accuracy: 0.9852 - val_loss: 0.3612 - val_auc: 0.9246 - val_f1_score: 0.8313 - val_accuracy: 0.8378 - lr: 0.0010\n",
      "Epoch 12/30\n",
      "29/29 [==============================] - 4s 132ms/step - loss: 0.0568 - auc: 0.9994 - f1_score: 0.9891 - accuracy: 0.9891 - val_loss: 0.3497 - val_auc: 0.9297 - val_f1_score: 0.8551 - val_accuracy: 0.8575 - lr: 0.0010\n",
      "Epoch 13/30\n",
      "29/29 [==============================] - 4s 129ms/step - loss: 0.0414 - auc: 0.9998 - f1_score: 0.9959 - accuracy: 0.9959 - val_loss: 0.3752 - val_auc: 0.9250 - val_f1_score: 0.8415 - val_accuracy: 0.8452 - lr: 0.0010\n",
      "Epoch 14/30\n",
      "29/29 [==============================] - ETA: 0s - loss: 0.0328 - auc: 0.9999 - f1_score: 0.9962 - accuracy: 0.9962\n",
      "Epoch 14: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\n",
      "Restoring model weights from the end of the best epoch: 9.\n",
      "29/29 [==============================] - 4s 130ms/step - loss: 0.0328 - auc: 0.9999 - f1_score: 0.9962 - accuracy: 0.9962 - val_loss: 0.3548 - val_auc: 0.9305 - val_f1_score: 0.8702 - val_accuracy: 0.8698 - lr: 0.0010\n",
      "Epoch 14: early stopping\n",
      "15/15 [==============================] - 0s 9ms/step - loss: 0.3872 - auc: 0.9071 - f1_score: 0.8079 - accuracy: 0.8071\n"
     ]
    }
   ],
   "source": [
    "# his = model.fit(train_x, train_y, val_x, val_y)\n",
    "# res = model.evaluate(test_x, test_y)\n",
    "his,res,avg = model.run_n_times(train_x, train_y, test_x, test_y, val_x, val_y, n=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "train",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
