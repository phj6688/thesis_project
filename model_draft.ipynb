{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# C  N  N\n",
    "# ==========================================================="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow.keras.backend as K\n",
    "import tensorflow.keras.layers as layers\n",
    "import tensorflow.keras.regularizers as regularizers\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.callbacks import TensorBoard\n",
    "import tensorflow_addons as tfa\n",
    "from datetime import datetime\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "import pickle\n",
    "import os\n",
    "import json\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = ''\n",
    "np.random.seed(100)\n",
    "import random\n",
    "random.seed(100)\n",
    "tf.random.set_seed(100)\n",
    "\n",
    "class CNN:\n",
    "    def __init__(self,dims,w2v_path,max_seq_len=20,batch_size=128,epochs=20):\n",
    "        self.dims = dims\n",
    "        self.max_seq_len = max_seq_len\n",
    "        self.batch_size = batch_size\n",
    "        self.epochs = epochs\n",
    "        with open(w2v_path, 'rb') as f:            \n",
    "            self.w2v = pickle.load(f)\n",
    "        self.model = None        \n",
    "        self.label_mapping = None\n",
    "        self.n_classes = None\n",
    "        self.history = None\n",
    "        self.metrics = None #[tf.keras.metrics.AUC(name='auc'), tfa.metrics.F1Score(self.n_classes, average='weighted', name='f1_score'), 'accuracy']\n",
    "        log_dir = f\"logs/fit/run_only_once\" + datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "        tensorboard_callback = TensorBoard(log_dir=log_dir, histogram_freq=1)\n",
    "        decay_rate = tf.keras.callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=5, verbose=1, mode='auto', min_delta=0.0001 ,min_lr=0.00001)\n",
    "        early_stopping = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=5, verbose=1, mode='auto', restore_best_weights=True)\n",
    "        self.callbacks = [tensorboard_callback, decay_rate, early_stopping]\n",
    "\n",
    "\n",
    "    def build_cnn(self):\n",
    "        if self.n_classes > 2:\n",
    "            loss = 'categorical_crossentropy'\n",
    "            activation = 'softmax'\n",
    "        else:\n",
    "            loss = 'binary_crossentropy'\n",
    "            activation = 'sigmoid'\n",
    "\n",
    "        input_layer = layers.Input(shape=(self.max_seq_len, 300))\n",
    "        conv1_1 = layers.Conv1D(128, 4, activation='relu', padding='same')(input_layer)\n",
    "        conv1_2 = layers.Conv1D(128, 5, activation='relu', padding='same')(conv1_1)\n",
    "        #conv1_3 = layers.Conv1D(128, 5, activation='relu', padding='same')(conv1_2)\n",
    "        conv_out = layers.Concatenate(axis=1)([conv1_1, conv1_2])\n",
    "\n",
    "        dropout_rate = 0.5\n",
    "        dropout_out1 = layers.Dropout(dropout_rate)(conv_out)\n",
    "\n",
    "        pool_out = layers.MaxPool1D(pool_size=self.max_seq_len, padding='valid')(dropout_out1)\n",
    "        flatten_out = layers.Flatten()(pool_out)\n",
    "        dropout_out2 = layers.Dropout(dropout_rate)(flatten_out)\n",
    "        dense_out = layers.Dense(self.n_classes, activation=activation, kernel_regularizer=regularizers.L2(0.001))(dropout_out2)\n",
    "        \n",
    "        self.metrics = [tf.keras.metrics.AUC(name='auc'), tfa.metrics.F1Score(self.n_classes, average='weighted', name='f1_score'), 'accuracy']\n",
    "        cnn_model = Model(inputs=input_layer, outputs=dense_out)\n",
    "        cnn_model.compile(optimizer='adam', loss=loss, metrics=self.metrics)\n",
    "        #cnn_model.summary()\n",
    "        self.model = cnn_model\n",
    "        \n",
    "    def insert_values(self,train_path,test_path):    \n",
    "        def insert(df):\n",
    "            \n",
    "            # initialize x self.and y matrices\n",
    "            num_lines = len(df)\n",
    "            self.n_classes = df['class'].nunique()          \n",
    "            x_matrix = np.zeros((num_lines, self.max_seq_len ,300))\n",
    "            y_matrix = np.zeros((num_lines, self.n_classes))\n",
    "\n",
    "\n",
    "            # insert values\n",
    "            for i, row in df.iterrows():\n",
    "                label = row[0]\n",
    "                sentence = row[1]\n",
    "                if isinstance(sentence, str):\n",
    "                    words = sentence.split()[:self.max_seq_len]\n",
    "                    for j, word in enumerate(words):\n",
    "                        if word in self.w2v:\n",
    "                            x_matrix[i, j, :] = self.w2v[word]\n",
    "                else:\n",
    "                    continue        \n",
    "                y_matrix[i,label] = 1.0    \n",
    "\n",
    "            return x_matrix,y_matrix\n",
    "        \n",
    "        train_df = pd.read_csv(train_path)\n",
    "        test_df = pd.read_csv(test_path)\n",
    "\n",
    "        self.n_classes = train_df['class'].nunique()        \n",
    "        unique_classes = train_df['class'].unique()\n",
    "        labels_map = dict(zip(unique_classes, range(self.n_classes)))\n",
    "\n",
    "        train_df['class'] = train_df['class'].map(labels_map)\n",
    "        test_df['class'] = test_df['class'].map(labels_map)\n",
    "\n",
    "        train_df, val_df = train_test_split(train_df, test_size=0.1, random_state=100)\n",
    "        print(f'Train size: {len(train_df)}\\nValidation size: {len(val_df)}\\nTest size: {len(test_df)}')\n",
    "\n",
    "        train_df = train_df.sample(frac=1).reset_index(drop=True)\n",
    "        test_df = test_df.sample(frac=1).reset_index(drop=True)\n",
    "        val_df = val_df.sample(frac=1,random_state=100).reset_index(drop=True)\n",
    "\n",
    "        train_x, train_y = insert(train_df)\n",
    "        test_x, test_y = insert(test_df)\n",
    "        val_x, val_y = insert(val_df)\n",
    "\n",
    "        return train_x, train_y, test_x, test_y, val_x, val_y, self.n_classes          \n",
    "\n",
    "    def fit(self,train_x, train_y,  val_x, val_y):\n",
    "        self.metrics = [tf.keras.metrics.AUC(name='auc'), tfa.metrics.F1Score(self.n_classes, average='weighted', name='f1_score'), 'accuracy']\n",
    "        self.build_cnn()  \n",
    "        self.history = self.model.fit(train_x, train_y, batch_size=self.batch_size, epochs=self.epochs, validation_data=(val_x, val_y), callbacks=self.callbacks, verbose=0)\n",
    "        return self.history\n",
    "    def evaluate(self,test_x, test_y):\n",
    "        return self.model.evaluate(test_x, test_y,return_dict=True)\n",
    "\n",
    "\n",
    "\n",
    "    def run_n_times(self,train_x, train_y, test_x, test_y, val_x, val_y, dataset_name, n=3):\n",
    "            hist_dict = {}\n",
    "            res_dict = {}\n",
    "            best_val_loss = float('inf')\n",
    "            for i in range(n):\n",
    "                print(f'Run {i+1} of {n}')\n",
    "                self.fit(train_x, train_y, val_x, val_y)\n",
    "                res = self.evaluate(test_x, test_y)\n",
    "                res_dict[i+1] = res\n",
    "                if self.history.history['val_loss'][-1] < best_val_loss:\n",
    "                    best_val_loss = self.history.history['val_loss'][-1]\n",
    "                    self.model.save(f\"models/{dataset_name}_best_model.h5\")\n",
    "                self.model.set_weights([np.zeros(w.shape) for w in self.model.get_weights()])\n",
    "            \n",
    "            avg_dict = {metric: round(sum(values[metric] for values in res_dict.values()) / len(res_dict), 4)  for metric in res_dict[1].keys()}\n",
    "            \n",
    "            # Save the average results to disk\n",
    "            os.makedirs(\"results\", exist_ok=True)\n",
    "            with open(f\"results/{dataset_name}_avg_results.txt\", \"w\") as f:\n",
    "                for key, value in avg_dict.items():\n",
    "                    f.write(f\"{key}: {value}\\n\")\n",
    "            \n",
    "            K.clear_session()\n",
    "            \n",
    "            return hist_dict, res_dict, avg_dict\n",
    "\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN:\n",
    "    def __init__(self,dims,w2v_path,max_seq_len=20,batch_size=128,epochs=20,batch_size_insert=1000):\n",
    "        self.dims = dims\n",
    "        self.max_seq_len = max_seq_len\n",
    "        self.batch_size = batch_size\n",
    "        self.batch_size_insert = batch_size_insert\n",
    "        self.epochs = epochs\n",
    "        with open(w2v_path, 'rb') as f:            \n",
    "            self.w2v = pickle.load(f)\n",
    "        self.model = None        \n",
    "        self.label_mapping = None\n",
    "        self.n_classes = None\n",
    "        self.history = None\n",
    "        self.metrics = None #[tf.keras.metrics.AUC(name='auc'), tfa.metrics.F1Score(self.n_classes, average='weighted', name='f1_score'), 'accuracy']        \n",
    "        self.callbacks =None\n",
    "        \n",
    "\n",
    "\n",
    "    def build_cnn(self):\n",
    "        if self.n_classes > 2:\n",
    "            loss = 'categorical_crossentropy'\n",
    "            activation = 'softmax'\n",
    "        else:\n",
    "            loss = 'binary_crossentropy'\n",
    "            activation = 'sigmoid'\n",
    "\n",
    "        input_layer = layers.Input(shape=(self.max_seq_len, 300))\n",
    "        conv1_1 = layers.Conv1D(128, 4, activation='relu', padding='same')(input_layer)\n",
    "        conv1_2 = layers.Conv1D(128, 5, activation='relu', padding='same')(conv1_1)\n",
    "        #conv1_3 = layers.Conv1D(128, 5, activation='relu', padding='same')(conv1_2)\n",
    "        conv_out = layers.Concatenate(axis=1)([conv1_1, conv1_2])\n",
    "\n",
    "        dropout_rate = 0.5\n",
    "        dropout_out1 = layers.Dropout(dropout_rate)(conv_out)\n",
    "\n",
    "        pool_out = layers.MaxPool1D(pool_size=self.max_seq_len, padding='valid')(dropout_out1)\n",
    "        flatten_out = layers.Flatten()(pool_out)\n",
    "        dropout_out2 = layers.Dropout(dropout_rate)(flatten_out)\n",
    "        dense_out = layers.Dense(self.n_classes, activation=activation, kernel_regularizer=regularizers.L2(0.001))(dropout_out2)\n",
    "        \n",
    "        self.metrics = [tf.keras.metrics.AUC(name='auc'), tfa.metrics.F1Score(self.n_classes, average='weighted', name='f1_score'), 'accuracy']\n",
    "        cnn_model = Model(inputs=input_layer, outputs=dense_out)\n",
    "        cnn_model.compile(optimizer='adam', loss=loss, metrics=self.metrics)\n",
    "        #cnn_model.summary()\n",
    "        self.model = cnn_model\n",
    "        \n",
    "    def insert_values(self,train_path,test_path):    \n",
    "        def insert(df):\n",
    "            \n",
    "            # initialize x self.and y matrices\n",
    "            num_lines = len(df)\n",
    "            self.n_classes = df['class'].nunique()          \n",
    "            x_matrix =        np.zeros((num_lines, self.max_seq_len ,300))\n",
    "            y_matrix = np.zeros((num_lines, self.n_classes))\n",
    "\n",
    "\n",
    "            # insert values\n",
    "            for i in range(0, num_lines, self.batch_size_insert):\n",
    "                df_batch = df.iloc[i:i+self.batch_size_insert]\n",
    "                batch_size = len(df_batch)\n",
    "                x_batch = np.zeros((batch_size, self.max_seq_len, 300))\n",
    "                y_batch = np.zeros((batch_size, self.n_classes))\n",
    "\n",
    "                for j, row in df_batch.iterrows():\n",
    "                    label = row[0]\n",
    "                    sentence = row[1]\n",
    "                    if isinstance(sentence, str):\n",
    "                        words = sentence.split()[:self.max_seq_len]\n",
    "                        for k, word in enumerate(words):\n",
    "                            if word in self.w2v:\n",
    "                                x_batch[j-i, k, :] = self.w2v[word]\n",
    "                    else:\n",
    "                        continue        \n",
    "                    y_batch[j-i,label] = 1.0\n",
    "\n",
    "                x_matrix[i:i+batch_size] = x_batch\n",
    "                y_matrix[i:i+batch_size] = y_batch\n",
    "\n",
    "            return x_matrix,y_matrix\n",
    "    \n",
    "        train_df = pd.read_csv(train_path)\n",
    "        test_df = pd.read_csv(test_path)\n",
    "\n",
    "        self.n_classes = train_df['class'].nunique()        \n",
    "        unique_classes = train_df['class'].unique()\n",
    "        labels_map = dict(zip(unique_classes, range(self.n_classes)))\n",
    "\n",
    "        train_df['class'] = train_df['class'].map(labels_map)\n",
    "        test_df['class'] = test_df['class'].map(labels_map)\n",
    "\n",
    "        train_df, val_df = train_test_split(train_df, test_size=0.1, random_state=100)\n",
    "        print(f'Train size: {len(train_df)}\\nValidation size: {len(val_df)}\\nTest size: {len(test_df)}')\n",
    "\n",
    "        train_df = train_df.sample(frac=1).reset_index(drop=True)\n",
    "        test_df = test_df.sample(frac=1).reset_index(drop=True)\n",
    "        val_df = val_df.sample(frac=1,random_state=100).reset_index(drop=True)\n",
    "\n",
    "        train_x, train_y = insert(train_df)\n",
    "        test_x, test_y = insert(test_df)\n",
    "        val_x, val_y = insert(val_df)\n",
    "\n",
    "        return train_x, train_y, test_x, test_y, val_x, val_y, self.n_classes          \n",
    "\n",
    "    def fit(self,train_x, train_y,  val_x, val_y):\n",
    "        self.metrics = [tf.keras.metrics.AUC(name='auc'), tfa.metrics.F1Score(self.n_classes, average='weighted', name='f1_score'), 'accuracy']\n",
    "        self.build_cnn()  \n",
    "        self.history = self.model.fit(train_x, train_y, batch_size=self.batch_size, epochs=self.epochs, validation_data=(val_x, val_y), callbacks=self.callbacks, verbose=0)\n",
    "        return self.history\n",
    "    def evaluate(self,test_x, test_y):\n",
    "        return self.model.evaluate(test_x, test_y,return_dict=True)\n",
    "\n",
    "\n",
    "\n",
    "    def run_n_times(self,train_x, train_y, test_x, test_y, val_x, val_y, dataset_name, n=3):\n",
    "        \n",
    "        log_dir = f\"logs/fit/{dataset_name}/\" + datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "        tensorboard_callback = TensorBoard(log_dir=log_dir, histogram_freq=1)\n",
    "        decay_rate = tf.keras.callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=5, verbose=1, mode='auto', min_delta=0.0001 ,min_lr=0.00001)\n",
    "        early_stopping = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=5, verbose=1, mode='auto', restore_best_weights=True)\n",
    "        self.callbacks = [tensorboard_callback, decay_rate, early_stopping]\n",
    "\n",
    "        hist_dict = {}\n",
    "        res_dict = {}\n",
    "        best_val_loss = float('inf')\n",
    "        for i in range(n):\n",
    "            print(f'Run {i+1} of {n}')\n",
    "            try:\n",
    "                self.fit(train_x, train_y, val_x, val_y)\n",
    "            except tf.errors.ResourceExhaustedError:\n",
    "                K.clear_session()\n",
    "                self.model = None\n",
    "                self.build_cnn()\n",
    "                continue\n",
    "            res = self.evaluate(test_x, test_y)\n",
    "            res_dict[i+1] = res\n",
    "            if self.history.history['val_loss'][-1] < best_val_loss:\n",
    "                best_val_loss = self.history.history['val_loss'][-1]\n",
    "                self.model.save(f\"models/{dataset_name}_best_model.h5\")\n",
    "            self.model.set_weights([np.zeros(w.shape) for w in self.model.get_weights()])\n",
    "        \n",
    "        avg_dict = {metric: round(sum(values[metric] for values in res_dict.values()) / len(res_dict), 4)  for metric in res_dict[1].keys()}\n",
    "        \n",
    "        # Save the average results to disk\n",
    "        os.makedirs(\"results\", exist_ok=True)\n",
    "        with open(f\"results/{dataset_name}_avg_results.txt\", \"w\") as f:\n",
    "            for key, value in avg_dict.items():\n",
    "                f.write(f\"{key}: {value}\\n\")\n",
    "        \n",
    "        K.clear_session()\n",
    "        \n",
    "        return hist_dict, res_dict, avg_dict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_path  = 'data/original/agnews/train.csv'\n",
    "test_path   = 'data/original/agnews/test.csv'\n",
    "w2v_path = 'w2v.pkl'\n",
    "name = 'agnews'\n",
    "max_seq_len = 150\n",
    "batch_size = 8\n",
    "epochs = 30\n",
    "cnn = CNN(dims=300, w2v_path=w2v_path, max_seq_len=20, batch_size=128, epochs=20)\n",
    "train_x, train_y, test_x, test_y, val_x, val_y, n_classes = cnn.insert_values(train_path,test_path)\n",
    "hist_dict, res_dict, avg_dict = cnn.run_n_times(train_x, train_y, test_x, test_y, val_x, val_y, name, n=3)\n",
    "\n",
    "\n",
    "# model = CNN(dims=300, max_seq_len=max_seq_len, batch_size=batch_size, epochs=epochs, w2v_path=w2v_path)\n",
    "# train_x, train_y, test_x, test_y, val_x, val_y, n_classes = model.insert_values(train_path,test_path)\n",
    "# his,res,avg = model.run_n_times(train_x, train_y, test_x, test_y, val_x, val_y, n=3)\n",
    "# print (avg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow.keras.backend as K\n",
    "import tensorflow.keras.layers as layers\n",
    "import tensorflow.keras.regularizers as regularizers\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.callbacks import TensorBoard\n",
    "import tensorflow_addons as tfa\n",
    "from datetime import datetime\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "import pickle\n",
    "import os\n",
    "import json\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = ''\n",
    "np.random.seed(100)\n",
    "import random\n",
    "random.seed(100)\n",
    "tf.random.set_seed(100)\n",
    "\n",
    "\n",
    "\n",
    "class LSTM:\n",
    "    def __init__(self,dims,w2v_path,max_seq_len=20,batch_size=128,epochs=20,chunk_size=1000):\n",
    "        self.dims = dims\n",
    "        self.max_seq_len = max_seq_len\n",
    "        self.batch_size = batch_size\n",
    "        self.chunk_size = chunk_size\n",
    "        self.epochs = epochs\n",
    "        with open(w2v_path, 'rb') as f:            \n",
    "            self.w2v = pickle.load(f)\n",
    "        self.model = None                \n",
    "        self.n_classes = None\n",
    "        self.history = None\n",
    "        self.metrics = None #[tf.keras.metrics.AUC(name='auc'), tfa.metrics.F1Score(self.n_classes, average='weighted', name='f1_score'), 'accuracy']        \n",
    "        self.callbacks =None\n",
    "        \n",
    "\n",
    "    def build_lstm(self):\n",
    "        if self.n_classes > 2:\n",
    "            loss = 'categorical_crossentropy'\n",
    "            activation = 'softmax'\n",
    "        else:\n",
    "            loss = 'binary_crossentropy'\n",
    "            activation = 'sigmoid'\n",
    "\n",
    "        input_layer = layers.Input(shape=(self.max_seq_len, 300))\n",
    "        lstm_1 = layers.Bidirectional(layers.LSTM(64, return_sequences=True))(input_layer)\n",
    "        dropout_rate = 0.5\n",
    "        dropout_out1 = layers.Dropout(dropout_rate)(lstm_1)\n",
    "        lstm_2 = layers.Bidirectional(layers.LSTM(32, return_sequences=False))(dropout_out1)\n",
    "        dropout_out2 = layers.Dropout(dropout_rate)(lstm_2)\n",
    "        dense_1 = layers.Dense(20, activation='relu')(dropout_out2)\n",
    "        dense_out = layers.Dense(self.n_classes, activation=activation, kernel_regularizer=regularizers.L2(0.001))(dense_1)\n",
    "        \n",
    "        self.metrics = [tf.keras.metrics.AUC(name='auc'), tfa.metrics.F1Score(self.n_classes, average='weighted', name='f1_score'), 'accuracy']\n",
    "        lstm_model = Model(inputs=input_layer, outputs=dense_out)\n",
    "        lstm_model.compile(optimizer='adam', loss=loss, metrics=self.metrics)\n",
    "        #lstm_model.summary()\n",
    "        self.model = lstm_model\n",
    "        \n",
    "    def insert_values(self,train_path,test_path):    \n",
    "        def insert(df):\n",
    "            \n",
    "            # initialize x self.and y matrices\n",
    "            num_lines = len(df)\n",
    "            self.n_classes = df['class'].nunique()          \n",
    "            x_matrix = np.zeros((num_lines, self.max_seq_len ,300))\n",
    "            y_matrix = np.zeros((num_lines, self.n_classes))\n",
    "\n",
    "\n",
    "            # insert values\n",
    "            for i in range(0, num_lines, self.chunk_size):\n",
    "                df_batch = df.iloc[i:i+self.chunk_size]\n",
    "                batch_size = len(df_batch)\n",
    "                x_batch = np.zeros((batch_size, self.max_seq_len, 300))\n",
    "                y_batch = np.zeros((batch_size, self.n_classes))\n",
    "\n",
    "                for j, row in df_batch.iterrows():\n",
    "                    label = row[0]\n",
    "                    sentence = row[1]\n",
    "                    if isinstance(sentence, str):\n",
    "                        words = sentence.split()[:self.max_seq_len]\n",
    "                        for k, word in enumerate(words):\n",
    "                            if word in self.w2v:\n",
    "                                x_batch[j-i, k, :] = self.w2v[word]\n",
    "                    else:\n",
    "                        continue        \n",
    "                    y_batch[j-i,label] = 1.0\n",
    "\n",
    "                x_matrix[i:i+batch_size] = x_batch\n",
    "                y_matrix[i:i+batch_size] = y_batch\n",
    "\n",
    "            return x_matrix,y_matrix\n",
    "    \n",
    "        train_df = pd.read_csv(train_path)\n",
    "        test_df = pd.read_csv(test_path)\n",
    "\n",
    "        self.n_classes = train_df['class'].nunique()        \n",
    "        unique_classes = train_df['class'].unique()\n",
    "        labels_map = dict(zip(unique_classes, range(self.n_classes)))\n",
    "\n",
    "        train_df['class'] = train_df['class'].map(labels_map)\n",
    "        test_df['class'] = test_df['class'].map(labels_map)\n",
    "\n",
    "        train_df, val_df = train_test_split(train_df, test_size=0.1, random_state=100)\n",
    "        print(f'Train size: {len(train_df)}\\nValidation size: {len(val_df)}\\nTest size: {len(test_df)}')\n",
    "\n",
    "        train_df = train_df.sample(frac=1).reset_index(drop=True)\n",
    "        test_df = test_df.sample(frac=1).reset_index(drop=True)\n",
    "        val_df = val_df.sample(frac=1,random_state=100).reset_index(drop=True)\n",
    "\n",
    "        train_x, train_y = insert(train_df)\n",
    "        test_x, test_y = insert(test_df)\n",
    "        val_x, val_y = insert(val_df)\n",
    "\n",
    "        return train_x, train_y, test_x, test_y, val_x, val_y, self.n_classes          \n",
    "\n",
    "    def fit(self,train_x, train_y,  val_x, val_y):\n",
    "        self.metrics = [tf.keras.metrics.AUC(name='auc'), tfa.metrics.F1Score(self.n_classes, average='weighted', name='f1_score'), 'accuracy']\n",
    "        self.build_lstm()  \n",
    "        self.history = self.model.fit(train_x, train_y, batch_size=self.batch_size, epochs=self.epochs, validation_data=(val_x, val_y), callbacks=self.callbacks, verbose=0)\n",
    "        return self.history\n",
    "    def evaluate(self,test_x, test_y):\n",
    "        return self.model.evaluate(test_x, test_y,return_dict=True)\n",
    "\n",
    "\n",
    "\n",
    "    def run_n_times(self,train_x, train_y, test_x, test_y, val_x, val_y, dataset_name, n=3):\n",
    "        \n",
    "        log_dir = f\"logs/fit/{dataset_name}/\" + datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "        tensorboard_callback = TensorBoard(log_dir=log_dir, histogram_freq=1)\n",
    "        decay_rate = tf.keras.callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=5, verbose=1, mode='auto', min_delta=0.0001 ,min_lr=0.00001)\n",
    "        early_stopping = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=5, verbose=1, mode='auto', restore_best_weights=True)\n",
    "        self.callbacks = [tensorboard_callback, decay_rate, early_stopping]\n",
    "\n",
    "        hist_dict = {}\n",
    "        res_dict = {}\n",
    "        best_val_loss = float('inf')\n",
    "        for i in range(n):\n",
    "            print(f'Run {i+1} of {n}')\n",
    "            try:\n",
    "                self.fit(train_x, train_y, val_x, val_y)\n",
    "            except tf.errors.ResourceExhaustedError:\n",
    "                K.clear_session()\n",
    "                self.model = None\n",
    "                self.build_lstm()\n",
    "                continue\n",
    "            res = self.evaluate(test_x, test_y)\n",
    "            res_dict[i+1] = res\n",
    "            if self.history.history['val_loss'][-1] < best_val_loss:\n",
    "                best_val_loss = self.history.history['val_loss'][-1]\n",
    "                self.model.save(f\"models/{dataset_name}_best_model.h5\")\n",
    "            self.model.set_weights([np.zeros(w.shape) for w in self.model.get_weights()])\n",
    "        \n",
    "        avg_dict = {metric: round(sum(values[metric] for values in res_dict.values()) / len(res_dict), 4)  for metric in res_dict[1].keys()}\n",
    "        \n",
    "        # Save the average results to disk\n",
    "        os.makedirs(\"results\", exist_ok=True)\n",
    "        with open(f\"results/{dataset_name}_avg_results.txt\", \"w\") as f:\n",
    "            for key, value in avg_dict.items():\n",
    "                f.write(f\"{key}: {value}\\n\")\n",
    "        \n",
    "        K.clear_session()\n",
    "        \n",
    "        return hist_dict, res_dict, avg_dict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_path  = 'data/original/cr/train.csv'\n",
    "test_path   = 'data/original/cr/test.csv'\n",
    "w2v_path = 'w2v.pkl'\n",
    "name = 'cr'\n",
    "max_seq_len = 64\n",
    "batch_size = 128\n",
    "epochs = 30\n",
    "lstm = LSTM(dims=300, w2v_path=w2v_path, max_seq_len=max_seq_len, batch_size=batch_size, epochs=epochs)\n",
    "train_x, train_y, test_x, test_y, val_x, val_y, n_classes = lstm.insert_values(train_path,test_path)\n",
    "hist_dict, res_dict, avg_dict = lstm.run_n_times(train_x, train_y, test_x, test_y, val_x, val_y, name, n=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow.keras.backend as K\n",
    "import tensorflow.keras.layers as layers\n",
    "import tensorflow.keras.regularizers as regularizers\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.callbacks import TensorBoard\n",
    "import tensorflow_addons as tfa\n",
    "from datetime import datetime\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import os\n",
    "import json\n",
    "import random\n",
    "\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = ''\n",
    "np.random.seed(100)\n",
    "random.seed(100)\n",
    "tf.random.set_seed(100)\n",
    "\n",
    "\n",
    "class CNN:\n",
    "    def __init__(self, dims, w2v_path, max_seq_len=20, batch_size=128, epochs=20, chunk_size=1000):\n",
    "        self.dims = dims\n",
    "        self.max_seq_len = max_seq_len\n",
    "        self.batch_size = batch_size\n",
    "        self.chunk_size = chunk_size\n",
    "        self.epochs = epochs\n",
    "        with open(w2v_path, 'rb') as f:\n",
    "            self.w2v = pickle.load(f)\n",
    "        self.model = None\n",
    "        self.n_classes = None\n",
    "        self.history = None\n",
    "        self.metrics = None\n",
    "        self.callbacks = None\n",
    "\n",
    "    def build_cnn(self):\n",
    "        if self.n_classes > 2:\n",
    "            loss = 'categorical_crossentropy'\n",
    "            activation = 'softmax'\n",
    "        else:\n",
    "            loss = 'binary_crossentropy'\n",
    "            activation = 'sigmoid'\n",
    "\n",
    "        input_layer = layers.Input(shape=(self.max_seq_len, 300))\n",
    "        conv1_1 = layers.Conv1D(128, 4, activation='relu', padding='same')(input_layer)\n",
    "        conv1_2 = layers.Conv1D(128, 5, activation='relu', padding='same')(conv1_1)\n",
    "        #conv1_3 = layers.Conv1D(128, 5, activation='relu', padding='same')(conv1_2)\n",
    "        conv_out = layers.Concatenate(axis=1)([conv1_1, conv1_2])\n",
    "\n",
    "        dropout_rate = 0.5\n",
    "        dropout_out1 = layers.Dropout(dropout_rate)(conv_out)\n",
    "\n",
    "        pool_out = layers.MaxPool1D(pool_size=self.max_seq_len, padding='valid')(dropout_out1)\n",
    "        flatten_out = layers.Flatten()(pool_out)\n",
    "        dropout_out2 = layers.Dropout(dropout_rate)(flatten_out)\n",
    "        dense_out = layers.Dense(self.n_classes, activation=activation, kernel_regularizer=regularizers.L2(0.001))(dropout_out2)\n",
    "        \n",
    "        self.metrics = [tf.keras.metrics.AUC(name='auc'), tfa.metrics.F1Score(self.n_classes, average='weighted', name='f1_score'), 'accuracy']\n",
    "        cnn_model = Model(inputs=input_layer, outputs=dense_out)\n",
    "        cnn_model.compile(optimizer='adam', loss=loss, metrics=self.metrics)\n",
    "        #cnn_model.summary()\n",
    "        self.model = cnn_model\n",
    "\n",
    "    def prepare_dataset(self, df):\n",
    "        def generator():\n",
    "            for _, row in df.iterrows():\n",
    "                label = row[0]\n",
    "                sentence = row[1]\n",
    "                x = np.zeros((self.max_seq_len, 300))\n",
    "                y = np.zeros(self.n_classes)\n",
    "\n",
    "                if isinstance(sentence, str):\n",
    "                    words = sentence.split()[:self.max_seq_len]\n",
    "                    for k, word in enumerate(words):\n",
    "                        if word in self.w2v:\n",
    "                            x[k, :] = self.w2v[word]\n",
    "                y[label] = 1.0\n",
    "                yield x, y\n",
    "\n",
    "        dataset = tf.data.Dataset.from_generator(\n",
    "            generator,\n",
    "            output_signature=(\n",
    "                tf.TensorSpec(shape=(self.max_seq_len, 300), dtype=tf.float32),\n",
    "                tf.TensorSpec(shape=(self.n_classes,), dtype=tf.float32)\n",
    "            )\n",
    "        )\n",
    "        return dataset\n",
    "\n",
    "\n",
    "    def insert_values(self, train_path, test_path):\n",
    "        train_df = pd.read_csv(train_path)\n",
    "        test_df = pd.read_csv(test_path)\n",
    "\n",
    "        self.n_classes = train_df['class'].nunique()\n",
    "        unique_classes = train_df['class'].unique()\n",
    "        labels_map = dict(zip(unique_classes, range(self.n_classes)))\n",
    "\n",
    "        train_df['class'] = train_df['class'].map(labels_map)\n",
    "        test_df['class'] = test_df['class'].map(labels_map)\n",
    "\n",
    "        train_df, val_df = train_test_split(train_df, test_size=0.1, random_state=100)\n",
    "        print(f'Train size: {len(train_df)}\\nValidation size: {len(val_df)}\\nTest size: {len(test_df)}')\n",
    "\n",
    "        train_df = train_df.sample(frac=1).reset_index(drop=True)\n",
    "        test_df = test_df.sample(frac=1).reset_index(drop=True)\n",
    "        val_df = val_df.sample(frac=1, random_state=100).reset_index(drop=True)\n",
    "\n",
    "        train_dataset = self.prepare_dataset(train_df).batch(self.batch_size).prefetch(buffer_size=tf.data.AUTOTUNE)\n",
    "        test_dataset = self.prepare_dataset(test_df).batch(self.batch_size).prefetch(buffer_size=tf.data.AUTOTUNE)\n",
    "        val_dataset = self.prepare_dataset(val_df).batch(self.batch_size).prefetch(buffer_size=tf.data.AUTOTUNE)\n",
    "\n",
    "        return train_dataset, test_dataset, val_dataset, self.n_classes\n",
    "\n",
    "    def fit(self, train_dataset, val_dataset):\n",
    "        self.metrics = [tf.keras.metrics.AUC(name='auc'), tfa.metrics.F1Score(self.n_classes, average='weighted', name='f1_score'), 'accuracy']\n",
    "        self.build_cnn()\n",
    "        self.history = self.model.fit(train_dataset, epochs=self.epochs, validation_data=val_dataset, callbacks=self.callbacks, verbose=0)\n",
    "        return self.history\n",
    "\n",
    "    def evaluate(self, test_dataset):\n",
    "        return self.model.evaluate(test_dataset, return_dict=True)\n",
    "\n",
    "    def run_n_times(self, train_dataset, test_dataset, val_dataset, dataset_name, n=3):\n",
    "\n",
    "        log_dir = f\"logs/fit/{dataset_name}/\" + datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "        tensorboard_callback = TensorBoard(log_dir=log_dir, histogram_freq=1)\n",
    "        decay_rate = tf.keras.callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=5, verbose=1, mode='auto', min_delta=0.0001 ,min_lr=0.00001)\n",
    "        early_stopping = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=5, verbose=1, mode='auto', restore_best_weights=True)\n",
    "        self.callbacks = [tensorboard_callback, decay_rate, early_stopping]\n",
    "\n",
    "        hist_dict = {}\n",
    "        res_dict = {}\n",
    "        best_val_loss = float('inf')\n",
    "        for i in range(n):\n",
    "            print(f'Run {i+1} of {n}')\n",
    "            try:\n",
    "                self.fit(train_dataset, val_dataset)  # Updated to use train_dataset and val_dataset\n",
    "            except tf.errors.ResourceExhaustedError:\n",
    "                K.clear_session()\n",
    "                self.model = None\n",
    "                self.build_cnn()\n",
    "                continue\n",
    "            res = self.evaluate(test_dataset)  # Updated to use test_dataset\n",
    "            res_dict[i+1] = res\n",
    "            if self.history.history['val_loss'][-1] < best_val_loss:\n",
    "                best_val_loss = self.history.history['val_loss'][-1]\n",
    "                self.model.save(f\"models/{dataset_name}_best_model.h5\")\n",
    "            self.model.set_weights([np.zeros(w.shape) for w in self.model.get_weights()])\n",
    "\n",
    "        avg_dict = {metric: round(sum(values[metric] for values in res_dict.values()) / len(res_dict), 4) for metric in res_dict[1].keys()}\n",
    "\n",
    "        # Save the average results to disk\n",
    "        os.makedirs(\"results\", exist_ok=True)\n",
    "        with open(f\"results/{dataset_name}_avg_results.txt\", \"w\") as f:\n",
    "            for key, value in avg_dict.items():\n",
    "                f.write(f\"{key}: {value}\\n\")\n",
    "\n",
    "        K.clear_session()\n",
    "\n",
    "        return hist_dict, res_dict, avg_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "name = 'cardio'\n",
    "train_path = f'data/original/{name}/train.csv'\n",
    "test_path = f'data/original/{name}/test.csv'\n",
    "w2v_path = 'w2v.pkl'\n",
    "dataset_name = f'{name}'\n",
    "max_seq_len = 64\n",
    "batch_size = 128\n",
    "epochs = 30\n",
    "\n",
    "cnn = CNN(dims=300, w2v_path=w2v_path, max_seq_len=max_seq_len, batch_size=batch_size, epochs=epochs, chunk_size=1000)\n",
    "train_dataset, test_dataset, val_dataset, n_classes = cnn.insert_values(train_path, test_path)  # Updated to return datasets\n",
    "hist_dict, res_dict, avg_dict = cnn.run_n_times(train_dataset, test_dataset, val_dataset, name, n=3)  # Updated to use datasets"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# = = = = =  = = = = = = =\n",
    "# L  S  T  M\n",
    "# = = = = = = = = = = = = "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow.keras.backend as K\n",
    "import tensorflow.keras.layers as layers\n",
    "import tensorflow.keras.regularizers as regularizers\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.callbacks import TensorBoard\n",
    "import tensorflow_addons as tfa\n",
    "from datetime import datetime\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import os\n",
    "import json\n",
    "import random\n",
    "\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = ''\n",
    "np.random.seed(100)\n",
    "random.seed(100)\n",
    "tf.random.set_seed(100)\n",
    "\n",
    "\n",
    "class LSTM:\n",
    "    def __init__(self, dims, w2v_path, max_seq_len=20, batch_size=128, epochs=20, chunk_size=1000):\n",
    "        self.dims = dims\n",
    "        self.max_seq_len = max_seq_len\n",
    "        self.batch_size = batch_size\n",
    "        self.chunk_size = chunk_size\n",
    "        self.epochs = epochs\n",
    "        with open(w2v_path, 'rb') as f:\n",
    "            self.w2v = pickle.load(f)\n",
    "        self.model = None\n",
    "        self.n_classes = None\n",
    "        self.history = None\n",
    "        self.metrics = None\n",
    "        self.callbacks = None\n",
    "\n",
    "    def build_lstm(self):\n",
    "        if self.n_classes > 2:\n",
    "            loss = 'categorical_crossentropy'\n",
    "            activation = 'softmax'\n",
    "        else:\n",
    "            loss = 'binary_crossentropy'\n",
    "            activation = 'sigmoid'\n",
    "\n",
    "        input_layer = layers.Input(shape=(self.max_seq_len, 300))\n",
    "        lstm_1 = layers.Bidirectional(layers.LSTM(64, return_sequences=True))(input_layer)\n",
    "        dropout_rate = 0.5\n",
    "        dropout_out1 = layers.Dropout(dropout_rate)(lstm_1)\n",
    "        lstm_2 = layers.Bidirectional(layers.LSTM(32, return_sequences=False))(dropout_out1)\n",
    "        dropout_out2 = layers.Dropout(dropout_rate)(lstm_2)\n",
    "        dense_1 = layers.Dense(20, activation='relu')(dropout_out2)\n",
    "        dense_out = layers.Dense(self.n_classes, activation=activation, kernel_regularizer=regularizers.L2(0.001))(dense_1)\n",
    "        \n",
    "        self.metrics = [tf.keras.metrics.AUC(name='auc'), tfa.metrics.F1Score(self.n_classes, average='weighted', name='f1_score'), 'accuracy']\n",
    "        lstm_model = Model(inputs=input_layer, outputs=dense_out)\n",
    "        lstm_model.compile(optimizer='adam', loss=loss, metrics=self.metrics)\n",
    "        #lstm_model.summary()\n",
    "        self.model = lstm_model\n",
    "\n",
    "    def prepare_dataset(self, df):\n",
    "        def generator():\n",
    "            for _, row in df.iterrows():\n",
    "                label = row[0]\n",
    "                sentence = row[1]\n",
    "                x = np.zeros((self.max_seq_len, 300))\n",
    "                y = np.zeros(self.n_classes)\n",
    "\n",
    "                if isinstance(sentence, str):\n",
    "                    words = sentence.split()[:self.max_seq_len]\n",
    "                    for k, word in enumerate(words):\n",
    "                        if word in self.w2v:\n",
    "                            x[k, :] = self.w2v[word]\n",
    "                y[label] = 1.0\n",
    "                yield x, y\n",
    "\n",
    "        dataset = tf.data.Dataset.from_generator(\n",
    "            generator,\n",
    "            output_signature=(\n",
    "                tf.TensorSpec(shape=(self.max_seq_len, 300), dtype=tf.float32),\n",
    "                tf.TensorSpec(shape=(self.n_classes,), dtype=tf.float32)\n",
    "            )\n",
    "        )\n",
    "        return dataset\n",
    "\n",
    "\n",
    "    def insert_values(self, train_path, test_path):\n",
    "        train_df = pd.read_csv(train_path)\n",
    "        test_df = pd.read_csv(test_path)\n",
    "\n",
    "        self.n_classes = train_df['class'].nunique()\n",
    "        unique_classes = train_df['class'].unique()\n",
    "        labels_map = dict(zip(unique_classes, range(self.n_classes)))\n",
    "\n",
    "        train_df['class'] = train_df['class'].map(labels_map)\n",
    "        test_df['class'] = test_df['class'].map(labels_map)\n",
    "\n",
    "        train_df, val_df = train_test_split(train_df, test_size=0.1, random_state=100)\n",
    "        print(f'Train size: {len(train_df)}\\nValidation size: {len(val_df)}\\nTest size: {len(test_df)}')\n",
    "\n",
    "        train_df = train_df.sample(frac=1).reset_index(drop=True)\n",
    "        test_df = test_df.sample(frac=1).reset_index(drop=True)\n",
    "        val_df = val_df.sample(frac=1, random_state=100).reset_index(drop=True)\n",
    "\n",
    "        train_dataset = self.prepare_dataset(train_df).batch(self.batch_size).prefetch(buffer_size=tf.data.AUTOTUNE)\n",
    "        test_dataset = self.prepare_dataset(test_df).batch(self.batch_size).prefetch(buffer_size=tf.data.AUTOTUNE)\n",
    "        val_dataset = self.prepare_dataset(val_df).batch(self.batch_size).prefetch(buffer_size=tf.data.AUTOTUNE)\n",
    "\n",
    "        return train_dataset, test_dataset, val_dataset, self.n_classes\n",
    "\n",
    "    def fit(self, train_dataset, val_dataset):\n",
    "        self.metrics = [tf.keras.metrics.AUC(name='auc'), tfa.metrics.F1Score(self.n_classes, average='weighted', name='f1_score'), 'accuracy']\n",
    "        self.build_lstm()\n",
    "        self.history = self.model.fit(train_dataset, epochs=self.epochs, validation_data=val_dataset, callbacks=self.callbacks, verbose=0)\n",
    "        return self.history\n",
    "\n",
    "    def evaluate(self, test_dataset):\n",
    "        return self.model.evaluate(test_dataset, return_dict=True)\n",
    "\n",
    "    def run_n_times(self, train_dataset, test_dataset, val_dataset, dataset_name, n=3):\n",
    "\n",
    "        log_dir = f\"logs/fit/{dataset_name}/\" + datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "        tensorboard_callback = TensorBoard(log_dir=log_dir, histogram_freq=1)\n",
    "        decay_rate = tf.keras.callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=5, verbose=1, mode='auto', min_delta=0.0001 ,min_lr=0.00001)\n",
    "        early_stopping = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=5, verbose=1, mode='auto', restore_best_weights=True)\n",
    "        self.callbacks = [tensorboard_callback, decay_rate, early_stopping]\n",
    "\n",
    "        hist_dict = {}\n",
    "        res_dict = {}\n",
    "        best_val_loss = float('inf')\n",
    "        for i in range(n):\n",
    "            print(f'Run {i+1} of {n}')\n",
    "            try:\n",
    "                self.fit(train_dataset, val_dataset)  # Updated to use train_dataset and val_dataset\n",
    "            except tf.errors.ResourceExhaustedError:\n",
    "                K.clear_session()\n",
    "                self.model = None\n",
    "                self.build_lstm()\n",
    "                continue\n",
    "            res = self.evaluate(test_dataset)  # Updated to use test_dataset\n",
    "            res_dict[i+1] = res\n",
    "            if self.history.history['val_loss'][-1] < best_val_loss:\n",
    "                best_val_loss = self.history.history['val_loss'][-1]\n",
    "                self.model.save(f\"models/lstm/{dataset_name}_best_model.h5\")\n",
    "            self.model.set_weights([np.zeros(w.shape) for w in self.model.get_weights()])\n",
    "\n",
    "        avg_dict = {metric: round(sum(values[metric] for values in res_dict.values()) / len(res_dict), 4) for metric in res_dict[1].keys()}\n",
    "\n",
    "        # Save the average results to disk\n",
    "        os.makedirs(\"results/lstm\", exist_ok=True)\n",
    "        with open(f\"results/lstm/{dataset_name}_avg_results.txt\", \"w\") as f:\n",
    "            for key, value in avg_dict.items():\n",
    "                f.write(f\"{key}: {value}\\n\")\n",
    "\n",
    "        K.clear_session()\n",
    "\n",
    "        return hist_dict, res_dict, avg_dict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "name = 'cr'\n",
    "train_path = f'data/original/{name}/train.csv'\n",
    "test_path = f'data/original/{name}/test.csv'\n",
    "w2v_path = 'w2v.pkl'\n",
    "dataset_name = f'{name}'\n",
    "max_seq_len = 128\n",
    "batch_size = 128\n",
    "epochs = 30\n",
    "\n",
    "lstm = LSTM(dims=300, w2v_path=w2v_path, max_seq_len=max_seq_len, batch_size=batch_size, epochs=epochs, chunk_size=1000)\n",
    "train_dataset, test_dataset, val_dataset, n_classes = lstm.insert_values(train_path, test_path)  # Updated to return datasets\n",
    "hist_dict, res_dict, avg_dict = lstm.run_n_times(train_dataset, test_dataset, val_dataset, name, n=3)  # Updated to use datasets"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# B   E   R   T\n",
    "# ==========================================================="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from scipy.special import softmax\n",
    "from sklearn.model_selection import train_test_split\n",
    "from transformers import BertTokenizer, BertForSequenceClassification, Trainer, TrainingArguments\n",
    "from sklearn.metrics import precision_recall_fscore_support, accuracy_score, roc_auc_score\n",
    "import os\n",
    "# disable wandb\n",
    "os.environ[\"WANDB_DISABLED\"] = \"true\"\n",
    "\n",
    "train_path = 'data/original/cr/train.csv'\n",
    "test_path = 'data/original/cr/test.csv'\n",
    "# Load data\n",
    "train_data = pd.read_csv(train_path).sample(frac=1).reset_index(drop=True)\n",
    "test_data = pd.read_csv(test_path)\n",
    "\n",
    "encoder = LabelEncoder()\n",
    "train_data['class'] = encoder.fit_transform(train_data['class'])\n",
    "test_data['class'] = encoder.transform(test_data['class'])\n",
    "# Remove rows with missing or invalid 'text' values\n",
    "train_data = train_data[train_data['text'].apply(lambda x: isinstance(x, str))]\n",
    "test_data = test_data[test_data['text'].apply(lambda x: isinstance(x, str))]\n",
    "    \n",
    "# Load tokenizer and model\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "model = BertForSequenceClassification.from_pretrained('bert-base-uncased', num_labels=len(train_data['class'].unique()))\n",
    "\n",
    "# Tokenize data\n",
    "train_encodings = tokenizer(train_data['text'].tolist(), truncation=True, padding=True, max_length=512)\n",
    "test_encodings = tokenizer(test_data['text'].tolist(), truncation=True, padding=True,max_length=512)\n",
    "\n",
    "# Create dataset class\n",
    "class SimpleDataset:\n",
    "    def __init__(self, encodings, labels):\n",
    "        self.encodings = encodings\n",
    "        self.labels = labels\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        item = {key: val[idx] for key, val in self.encodings.items()}\n",
    "        item['labels'] = self.labels[idx]\n",
    "        return item\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "\n",
    "train_dataset = SimpleDataset(train_encodings, train_data['class'].tolist())\n",
    "test_dataset = SimpleDataset(test_encodings, test_data['class'].tolist())\n",
    "\n",
    "def compute_metrics(pred):\n",
    "    labels = pred.label_ids\n",
    "    preds = pred.predictions.argmax(-1)\n",
    "    probs = softmax(pred.predictions, axis=1)\n",
    "    precision, recall, f1, _ = precision_recall_fscore_support(labels, preds, average=\"weighted\")\n",
    "    accuracy = accuracy_score(labels, preds)\n",
    "    \n",
    "    # Calculate AUC\n",
    "    if len(np.unique(labels)) > 2:  # Multi-class case\n",
    "        auc = roc_auc_score(labels, probs, multi_class=\"ovo\", average=\"weighted\")\n",
    "    else:  # Binary case\n",
    "        auc = roc_auc_score(labels, probs[:, 1])  # Use the probability of the positive class\n",
    "\n",
    "    return {\n",
    "        \"accuracy\": accuracy,\n",
    "        \"f1\": f1,\n",
    "        \"precision\": precision,\n",
    "        \"recall\": recall,\n",
    "        \"auc\": auc\n",
    "    }\n",
    "# Training and evaluation\n",
    "training_args = TrainingArguments(\n",
    "    output_dir='./results/bert',\n",
    "    num_train_epochs=3,\n",
    "    per_device_train_batch_size=8,\n",
    "    per_device_eval_batch_size=16,\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    eval_steps=100,\n",
    "    logging_steps=10,\n",
    "    save_steps=0,\n",
    "    logging_dir='./logs/bert',\n",
    "    learning_rate=2e-5,\n",
    "    #fp16=True,\n",
    "   gradient_accumulation_steps = 8\n",
    "\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=test_dataset,\n",
    "    compute_metrics=compute_metrics\n",
    ")\n",
    "\n",
    "trainer.train()\n",
    "results = trainer.evaluate()\n",
    "print(\"Evaluation results:\", results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = trainer.predict(test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "pred = np.argmax(res.predictions, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_accuracy(y_predict, y_ground_truth):\n",
    "    assert len(y_predict) == len(y_ground_truth), \"Both lists must have the same length.\"\n",
    "\n",
    "    correct_predictions = 0\n",
    "\n",
    "    for pred, gt in zip(y_predict, y_ground_truth):\n",
    "        if pred == gt:\n",
    "            correct_predictions += 1\n",
    "\n",
    "    accuracy = correct_predictions / len(y_ground_truth) * 100\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_ground_truth = test_data['class'].tolist()\n",
    "y_predict = pred\n",
    "accuracy = calculate_accuracy(pred, y_ground_truth)\n",
    "print(f\"Accuracy: {accuracy:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = trainer.evaluate()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[i.split('_')[-1] for idx,i in enumerate(list(res.keys())) if idx < 6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_dict = {}\n",
    "order = ['loss', 'auc', 'f1','accuracy']\n",
    "for i in res:\n",
    "    if i.split('_')[-1] in order:\n",
    "        key = i.split('_')[-1]\n",
    "        new_dict[key] = res[i]#.__format__('0.4f')\n",
    "df = pd.DataFrame(new_dict, index=[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res_dict = {}\n",
    "avg_dict = {metric: round(sum(values[metric] for values in res_dict.values()) / len(res_dict), 4) for metric in res_dict[1].keys()}\n",
    "# Save the average results to disk\n",
    "import os\n",
    "os.makedirs(\"results/bert\", exist_ok=True)\n",
    "with open(f\"results/bert/{dataset_name}_avg_results.txt\", \"w\") as f:\n",
    "    for key, value in avg_dict.items():\n",
    "        f.write(f\"{key}: {value}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = pd.read_csv(train_path).sample(frac=1).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data['class'].nunique(), len(train_data['class'].unique())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## =========Bert V2 ========="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from transformers import DistilBertTokenizerFast ,DistilBertForSequenceClassification# AdamW\n",
    "from torch.optim import AdamW\n",
    "import torch\n",
    "from numpy import mean\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "from tqdm.auto import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_path = 'data/original/cr/train.csv'\n",
    "test_path = 'data/original/cr/test.csv'\n",
    "# Load data\n",
    "train_data = pd.read_csv(train_path).sample(frac=1).reset_index(drop=True)\n",
    "test_data = pd.read_csv(test_path).sample(frac=1).reset_index(drop=True)\n",
    "train_texts = train_data['text'].tolist()\n",
    "train_labels = train_data['class'].tolist()\n",
    "test_texts = test_data['text'].tolist()\n",
    "test_labels = test_data['class'].tolist()\n",
    "\n",
    "print(f\"Number of training examples: {len(train_texts)}\")\n",
    "print(f\"Number of test examples: {len(test_texts)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = DistilBertTokenizerFast.from_pretrained('distilbert-base-uncased')\n",
    "train_encodings = tokenizer(train_texts, truncation=True, padding=True)\n",
    "test_encodings = tokenizer(test_texts, truncation=True, padding=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, encodings, labels):\n",
    "        self.encodings = encodings\n",
    "        self.labels = labels\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
    "        item['labels'] = torch.tensor(self.labels[idx])\n",
    "        return item\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parameters\n",
    "num_of_epochs = 3\n",
    "learning_rate = 10e-6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = Dataset(train_encodings, train_labels)\n",
    "test_dataset = Dataset(test_encodings, test_labels)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=8, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=8, shuffle=True)\n",
    "\n",
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model\n",
    "model = DistilBertForSequenceClassification.from_pretrained('distilbert-base-uncased')\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#optimizer\n",
    "optimizer = AdamW(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(data_loader, model, optimizer):\n",
    "    model.train()\n",
    "    epoch_loss = 0\n",
    "    size = len(data_loader.dataset)\t\n",
    "    for i,batch in enumerate(data_loader):\n",
    "        input_ids = batch['input_ids'].to(device)\n",
    "        attention_mask = batch['attention_mask'].to(device)\n",
    "        labels = batch['labels'].to(device)\n",
    "        outputs = model(input_ids, attention_mask=attention_mask, labels=labels)\n",
    "        optimizer.zero_grad()\n",
    "        loss = outputs.loss\n",
    "        epoch_loss += loss.item()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    print(f\"Train loss: {epoch_loss/size:.4f}\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(data_loader, model):\n",
    "    model.eval()\n",
    "    size = len(data_loader.dataset)\n",
    "    test_loss, accuracy = 0, 0\n",
    "    with torch.no_grad():\n",
    "        for batch in data_loader:\n",
    "            X, y = batch['input_ids'].to(device), batch['labels'].to(device)\n",
    "            pred = model(X,labels=y)\n",
    "            test_loss += pred.loss\n",
    "            accuracy += (pred.logits.softmax(1).argmax(1) == y).type(torch.float).sum().item()\n",
    "        test_loss /= size\n",
    "        accuracy /= size\n",
    "        print(f\"Test loss: \\n Accuracy: {(100*accuracy):>0.1f}%, Avg loss: {test_loss:>8f} \\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tqdm.write(\"Training the model...\")\n",
    "tqdm.pandas()\n",
    "for i in tqdm(range(num_of_epochs)):\n",
    "    print(f'Epoch {i+1}')\n",
    "    train(train_loader, model, optimizer)\n",
    "    test(test_loader, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import DistilBertTokenizerFast, DistilBertForSequenceClassification, Trainer, TrainingArguments\n",
    "import torch\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
    "import os\n",
    "os.environ[\"WANDB_DISABLED\"] = \"true\"\n",
    "\n",
    "train_path = 'data/original/cr/train.csv'\n",
    "test_path = 'data/original/cr/test.csv'\n",
    "# Load data\n",
    "train_data = pd.read_csv(train_path).sample(frac=1).reset_index(drop=True)\n",
    "test_data = pd.read_csv(test_path).sample(frac=1).reset_index(drop=True)\n",
    "train_texts = train_data['text'].tolist()\n",
    "train_labels = train_data['class'].tolist()\n",
    "test_texts = test_data['text'].tolist()\n",
    "test_labels = test_data['class'].tolist()\n",
    "\n",
    "print(f\"Number of training examples: {len(train_texts)}\")\n",
    "print(f\"Number of test examples: {len(test_texts)}\")\n",
    "\n",
    "# Tokenize data\n",
    "tokenizer = DistilBertTokenizerFast.from_pretrained('distilbert-base-uncased')\n",
    "train_encodings = tokenizer(train_texts, truncation=True, padding=True)\n",
    "test_encodings = tokenizer(test_texts, truncation=True, padding=True)\n",
    "\n",
    "# Create PyTorch Dataset\n",
    "class TextDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, encodings, labels):\n",
    "        self.encodings = encodings\n",
    "        self.labels = labels\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
    "        item['labels'] = torch.tensor(self.labels[idx])\n",
    "        return item\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "train_dataset = TextDataset(train_encodings, train_labels)\n",
    "test_dataset = TextDataset(test_encodings, test_labels)\n",
    "\n",
    "# Define training arguments\n",
    "training_args = TrainingArguments(\n",
    "    output_dir='./results',\n",
    "    num_train_epochs=3,\n",
    "    per_device_train_batch_size=8,\n",
    "    per_device_eval_batch_size=8,\n",
    "    logging_dir='./logs',\n",
    "    logging_steps=10,\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model=\"accuracy\",\n",
    ")\n",
    "\n",
    "# Define model and trainer\n",
    "model = DistilBertForSequenceClassification.from_pretrained('distilbert-base-uncased', num_labels=len(set(train_labels)))\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=test_dataset,\n",
    "    compute_metrics=lambda p: {\"accuracy\": accuracy_score(p.label_ids, p.predictions.argmax(-1))}\n",
    ")\n",
    "\n",
    "# Train the model\n",
    "trainer.train()\n",
    "\n",
    "# Evaluate the model\n",
    "eval_results = trainer.evaluate()\n",
    "print(eval_results)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ======== BERT Combined ========"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification, Trainer, TrainingArguments\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support, roc_auc_score\n",
    "from scipy.special import softmax\n",
    "import torch\n",
    "\n",
    "os.environ[\"WANDB_DISABLED\"] = \"true\"\n",
    "\n",
    "class TextDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, encodings, labels):\n",
    "        self.encodings = encodings\n",
    "        self.labels = labels\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
    "        item['labels'] = torch.tensor(self.labels[idx])\n",
    "        return item\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "class TextClassifier:\n",
    "    def __init__(self, model_name, train_path, test_path, training_args):\n",
    "        self.model_name = model_name\n",
    "        self.tokenizer = AutoTokenizer.from_pretrained(self.model_name)\n",
    "        self.train_dataset, self.test_dataset, self.n_classes = self.prepare_dataset(train_path, test_path)\n",
    "        self.model = AutoModelForSequenceClassification.from_pretrained(self.model_name, num_labels=self.n_classes)\n",
    "        self.training_args = training_args\n",
    "        self.trainer = Trainer(\n",
    "            model=self.model,\n",
    "            args=self.training_args,\n",
    "            train_dataset=self.train_dataset,\n",
    "            eval_dataset=self.test_dataset,\n",
    "            compute_metrics=self.compute_metrics\n",
    "        )\n",
    "\n",
    "    def prepare_dataset(self, train_path, test_path):\n",
    "        train_data = pd.read_csv(train_path).sample(frac=1).reset_index(drop=True)\n",
    "        test_data = pd.read_csv(test_path).sample(frac=1).reset_index(drop=True)\n",
    "        encoder = LabelEncoder()\n",
    "        train_data['class'] = encoder.fit_transform(train_data['class'])\n",
    "        test_data['class'] = encoder.transform(test_data['class'])\n",
    "\n",
    "        train_encodings = self.tokenizer(train_data['text'].tolist(), truncation=True, padding=True)\n",
    "        test_encodings = self.tokenizer(test_data['text'].tolist(), truncation=True, padding=True)\n",
    "\n",
    "        train_dataset = TextDataset(train_encodings, train_data['class'].tolist())\n",
    "        test_dataset = TextDataset(test_encodings, test_data['class'].tolist())\n",
    "        n_classes = len(train_data['class'].unique())\n",
    "\n",
    "        return train_dataset, test_dataset, n_classes\n",
    "\n",
    "    def compute_metrics(self, pred):\n",
    "        labels = pred.label_ids\n",
    "        preds = pred.predictions.argmax(-1)\n",
    "        probs = softmax(pred.predictions, axis=1)\n",
    "        precision, recall, f1, _ = precision_recall_fscore_support(labels, preds, average=\"weighted\")\n",
    "        accuracy = accuracy_score(labels, preds)\n",
    "        auc = roc_auc_score(labels, probs, multi_class=\"ovo\", average=\"weighted\") if self.n_classes > 2 else roc_auc_score(labels, probs[:, 1])\n",
    "        return {\n",
    "            \"accuracy\": accuracy,\n",
    "            \"f1\": f1,\n",
    "            \"precision\": precision,\n",
    "            \"recall\": recall,\n",
    "            \"auc\": auc\n",
    "        }\n",
    "\n",
    "    def train_and_evaluate(self):\n",
    "        self.trainer.train()\n",
    "        eval_results = self.trainer.evaluate()\n",
    "        return eval_results\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir='./results',\n",
    "    num_train_epochs=3,\n",
    "    per_device_train_batch_size=8,\n",
    "    per_device_eval_batch_size=8,\n",
    "    logging_steps=10,\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model=\"f1\",\n",
    ")\n",
    "\n",
    "train_path = 'data/original/cr/train.csv'\n",
    "test_path = 'data/original/cr/test.csv'\n",
    "\n",
    "classifier = TextClassifier(\n",
    "    model_name='distilbert-base-uncased',\n",
    "    train_path=train_path,\n",
    "    test_path=test_path,\n",
    "    training_args=training_args\n",
    ")\n",
    "\n",
    "eval_results = classifier.train_and_evaluate()\n",
    "print(eval_results)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import shutil\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from scipy.special import softmax\n",
    "from sklearn.model_selection import train_test_split\n",
    "#from transformers import BertTokenizer, BertForSequenceClassification, Trainer, TrainingArguments\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification, Trainer, TrainingArguments\n",
    "from sklearn.metrics import precision_recall_fscore_support, accuracy_score, roc_auc_score\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "#set seed to 100 \n",
    "np.random.seed(100)\n",
    "\n",
    "\n",
    "\n",
    "# disable wandb\n",
    "os.environ[\"WANDB_DISABLED\"] = \"true\"\n",
    "\n",
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, encodings, labels):\n",
    "        self.encodings = encodings\n",
    "        self.labels = labels\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        item = {key: val[idx] for key, val in self.encodings.items()}\n",
    "        item['labels'] = torch.tensor(self.labels[idx])\n",
    "        return item\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "    \n",
    "class MyTrainer(Trainer):\n",
    "    def get_train_dataloader(self):\n",
    "        return self.train_dataloader\n",
    "\n",
    "    def get_eval_dataloader(self, eval_dataset=None):\n",
    "        return self.eval_dataloader\n",
    "\n",
    "class BERT:\n",
    "    def __init__(self, train_path, test_path, trainings_arguments: TrainingArguments, model_name='distilbert-base-uncased'):\n",
    "        # Define collate_fn\n",
    "        def collate_fn(batch):\n",
    "            keys = batch[0].keys()\n",
    "            output_batch = {}\n",
    "            for key in keys:\n",
    "                items = [item[key] for item in batch]\n",
    "                if isinstance(items[0], torch.Tensor):\n",
    "                    output_batch[key] = torch.stack(items)\n",
    "                else:\n",
    "                    output_batch[key] = torch.tensor(items)\n",
    "            return output_batch\n",
    "\n",
    "\n",
    "        \n",
    "        self.model_name = model_name\n",
    "        self.n_runs = None\n",
    "        self.best_val_loss = float('inf')\n",
    "        self.tokenizer = AutoTokenizer.from_pretrained(self.model_name)\n",
    "        self.trainings_arguments = trainings_arguments        \n",
    "        self.train_dataset, self.val_dataset, self.test_dataset, self.n_classes = self.prepare_dataset(train_path, test_path)\n",
    "        self.model = AutoModelForSequenceClassification.from_pretrained(self.model_name, num_labels=self.n_classes)\n",
    "        self.compute_metrics_func = self.compute_metrics\n",
    "        \n",
    "        # Create the DataLoaders\n",
    "        self.train_dataloader = DataLoader(self.train_dataset, batch_size=self.trainings_arguments.per_device_train_batch_size, shuffle=True, collate_fn=collate_fn)\n",
    "        self.val_dataloader = DataLoader(self.val_dataset, batch_size=self.trainings_arguments.per_device_eval_batch_size, shuffle=False, collate_fn=collate_fn)\n",
    "        self.test_dataloader = DataLoader(self.test_dataset, batch_size=self.trainings_arguments.per_device_eval_batch_size, shuffle=False, collate_fn=collate_fn)\n",
    "        \n",
    "        self.trainer = MyTrainer(\n",
    "            model=self.model,\n",
    "            args=self.trainings_arguments,\n",
    "            compute_metrics=self.compute_metrics_func)\n",
    "        \n",
    "        self.trainer.train_dataloader = self.train_dataloader\n",
    "        self.trainer.eval_dataloader = self.val_dataloader\n",
    "\n",
    "    \n",
    "   \n",
    "\n",
    "    def prepare_dataset(self, train_path, test_path):\n",
    "        train_data = pd.read_csv(train_path).sample(frac=1).reset_index(drop=True)\n",
    "        test_data = pd.read_csv(test_path).sample(frac=1).reset_index(drop=True)\n",
    "        n_classes = len(train_data['class'].unique())        \n",
    "        # encode the labels\n",
    "        encoder = LabelEncoder()\n",
    "        train_data['class'] = encoder.fit_transform(train_data['class'])\n",
    "        test_data['class'] = encoder.transform(test_data['class'])\n",
    "        # Remove rows with missing or invalid 'text' values\n",
    "        train_data = train_data[train_data['text'].apply(lambda x: isinstance(x, str))]\n",
    "        test_data = test_data[test_data['text'].apply(lambda x: isinstance(x, str))]        \n",
    "        \n",
    "        # Split train_data into train and validation sets\n",
    "        train_data, val_data = train_test_split(train_data, test_size=0.1, random_state=42, stratify=train_data['class'])\n",
    "\n",
    "        # tokenize the text\n",
    "        train_encodings = self.tokenizer(train_data['text'].tolist(), truncation=True, padding=True)\n",
    "        val_encodings = self.tokenizer(val_data['text'].tolist(), truncation=True, padding=True)\n",
    "        test_encodings = self.tokenizer(test_data['text'].tolist(), truncation=True, padding=True)\n",
    "        # create dataset\n",
    "        train_dataset = CustomDataset(train_encodings, train_data['class'].tolist())\n",
    "        val_dataset = CustomDataset(val_encodings, val_data['class'].tolist())\n",
    "        test_dataset = CustomDataset(test_encodings, test_data['class'].tolist())\n",
    "        return train_dataset, val_dataset, test_dataset, n_classes\n",
    "\n",
    "\n",
    "    def compute_metrics(self,pred):\n",
    "        labels = pred.label_ids\n",
    "        preds = pred.predictions.argmax(-1)\n",
    "        probs = softmax(pred.predictions, axis=1)\n",
    "        precision, recall, f1, _ = precision_recall_fscore_support(labels, preds, average=\"weighted\")\n",
    "        accuracy = accuracy_score(labels, preds)\n",
    "        \n",
    "        # Calculate AUC\n",
    "        if len(np.unique(labels)) > 2:  # Multi-class case\n",
    "            auc = roc_auc_score(labels, probs, multi_class=\"ovo\", average=\"weighted\")\n",
    "        else:  # Binary case\n",
    "            auc = roc_auc_score(labels, probs[:, 1])  # Use the probability of the positive class\n",
    "\n",
    "        return {\n",
    "            \"accuracy\": accuracy,\n",
    "            \"f1\": f1,\n",
    "            \"precision\": precision,\n",
    "            \"recall\": recall,\n",
    "            \"auc\": auc\n",
    "        }\n",
    "    \n",
    "    def train_and_evaluate(self, run_idx, dataset_name):\n",
    "        print(f'Run {run_idx} of {self.n_runs}')\n",
    "        # Load initial model state\n",
    "        self.model = AutoModelForSequenceClassification.from_pretrained(self.model_name, num_labels=self.n_classes)\n",
    "        self.trainer.model = self.model\n",
    "        self.trainer.train()\n",
    "        self.trainer.save_model(os.path.join(\"models\", \"bert\", f\"{dataset_name}_run_{run_idx}_model\"))\n",
    "        results = self.trainer.evaluate()\n",
    "        if results['eval_loss'] < self.best_val_loss:\n",
    "            self.best_val_loss = results['eval_loss']\n",
    "            self.trainer.save_model(os.path.join(\"models\", \"bert\", f\"{dataset_name}_best_model\"))\n",
    "            \n",
    "        return results\n",
    "\n",
    "\n",
    "    def clean_up_models(self, dataset_name):\n",
    "        for i in range(self.n_runs):\n",
    "            shutil.rmtree(f\"models/bert/{dataset_name}_run_{i+1}_model\")\n",
    "\n",
    "    def calculate_and_save_averages(self, res_dict, dataset_name):\n",
    "        avg_dict = {metric: round(sum(values[metric] for values in res_dict.values()) / len(res_dict), 4) for metric in res_dict[1].keys()}\n",
    "        order = ['loss', 'auc', 'f1', 'accuracy']\n",
    "        filtered_metrics = {i: avg_dict[f\"eval_{i}\"] for i in order if f\"eval_{i}\" in avg_dict}\n",
    "        os.makedirs(\"results/bert\", exist_ok=True)\n",
    "        with open(f\"results/bert/{dataset_name}_avg_results.txt\", \"w\") as f:\n",
    "            for key, value in filtered_metrics.items():\n",
    "                f.write(f\"{key}: {value}\\n\")\n",
    "        return filtered_metrics\n",
    "\n",
    "\n",
    "    def run_n_times(self, dataset_name, n=3):   \n",
    "        self.n_runs = n\n",
    "        self.best_val_loss = float('inf')\n",
    "        res_dict = {}\n",
    "\n",
    "        for i in range(n):\n",
    "            res_dict[i+1] = self.train_and_evaluate(i+1, dataset_name)\n",
    "            \n",
    "        self.clean_up_models(dataset_name)\n",
    "        avg_metrics = self.calculate_and_save_averages(res_dict, dataset_name)\n",
    "\n",
    "        return avg_metrics\n",
    "            \n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import TrainingArguments\n",
    "\n",
    "#dataset_list = ['trec','agnews', 'pc', 'yelp', 'cr', 'kaggle_med', 'cardio', 'bbc', 'sst2','subj']\n",
    "dataset_list = ['cr']\n",
    "\n",
    "\n",
    "for name in dataset_list:\n",
    "    try:\n",
    "        print(f'Running {name} dataset')\n",
    "        train_path  = f'data/original/{name}/train.csv'\n",
    "        test_path   = f'data/original/{name}/test.csv'\n",
    "        model_name = 'distilbert-base-uncased'\n",
    "        training_args = TrainingArguments(\n",
    "            output_dir='./models/bert',\n",
    "            num_train_epochs=3,\n",
    "            per_device_train_batch_size=8,\n",
    "            per_device_eval_batch_size=8,\n",
    "            evaluation_strategy=\"epoch\",\n",
    "            # eval_steps=100,\n",
    "            logging_steps=10,\n",
    "            # save_steps=0,\n",
    "            logging_dir='./logs/bert',\n",
    "            metric_for_best_model=\"f1\",\n",
    "            #learning_rate=2e-5,\n",
    "            seed=100\n",
    "        )\n",
    "\n",
    "\n",
    "\n",
    "        bert = BERT(train_path, test_path, training_args, model_name=model_name)            \n",
    "        avg_dict = bert.run_n_times(name, n=3)\n",
    "        print('---------------------------------------------------')\n",
    "        print(f'Average results for {name} dataset')\n",
    "        print(avg_dict)\n",
    "        print('---------------------------------------------------')\n",
    "    except Exception as e:\n",
    "        print(f'Error in {name}')\n",
    "        print(str(e))\n",
    "        continue\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch: setting up devices\n",
      "The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n",
      "Using the `WANDB_DISABLED` environment variable is deprecated and will be removed in v5. Use the --report_to flag to control the integrations used for logging result (for instance --report_to none).\n",
      "loading configuration file config.json from cache at /home/peyman/.cache/huggingface/hub/models--distilbert-base-uncased/snapshots/1c4513b2eedbda136f57676a34eea67aba266e5c/config.json\n",
      "Model config DistilBertConfig {\n",
      "  \"_name_or_path\": \"distilbert-base-uncased\",\n",
      "  \"activation\": \"gelu\",\n",
      "  \"architectures\": [\n",
      "    \"DistilBertForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.1,\n",
      "  \"dim\": 768,\n",
      "  \"dropout\": 0.1,\n",
      "  \"hidden_dim\": 3072,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"distilbert\",\n",
      "  \"n_heads\": 12,\n",
      "  \"n_layers\": 6,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"qa_dropout\": 0.1,\n",
      "  \"seq_classif_dropout\": 0.2,\n",
      "  \"sinusoidal_pos_embds\": false,\n",
      "  \"tie_weights_\": true,\n",
      "  \"transformers_version\": \"4.26.1\",\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "loading file vocab.txt from cache at /home/peyman/.cache/huggingface/hub/models--distilbert-base-uncased/snapshots/1c4513b2eedbda136f57676a34eea67aba266e5c/vocab.txt\n",
      "loading file tokenizer.json from cache at /home/peyman/.cache/huggingface/hub/models--distilbert-base-uncased/snapshots/1c4513b2eedbda136f57676a34eea67aba266e5c/tokenizer.json\n",
      "loading file added_tokens.json from cache at None\n",
      "loading file special_tokens_map.json from cache at None\n",
      "loading file tokenizer_config.json from cache at /home/peyman/.cache/huggingface/hub/models--distilbert-base-uncased/snapshots/1c4513b2eedbda136f57676a34eea67aba266e5c/tokenizer_config.json\n",
      "loading configuration file config.json from cache at /home/peyman/.cache/huggingface/hub/models--distilbert-base-uncased/snapshots/1c4513b2eedbda136f57676a34eea67aba266e5c/config.json\n",
      "Model config DistilBertConfig {\n",
      "  \"_name_or_path\": \"distilbert-base-uncased\",\n",
      "  \"activation\": \"gelu\",\n",
      "  \"architectures\": [\n",
      "    \"DistilBertForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.1,\n",
      "  \"dim\": 768,\n",
      "  \"dropout\": 0.1,\n",
      "  \"hidden_dim\": 3072,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"distilbert\",\n",
      "  \"n_heads\": 12,\n",
      "  \"n_layers\": 6,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"qa_dropout\": 0.1,\n",
      "  \"seq_classif_dropout\": 0.2,\n",
      "  \"sinusoidal_pos_embds\": false,\n",
      "  \"tie_weights_\": true,\n",
      "  \"transformers_version\": \"4.26.1\",\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "loading configuration file config.json from cache at /home/peyman/.cache/huggingface/hub/models--distilbert-base-uncased/snapshots/1c4513b2eedbda136f57676a34eea67aba266e5c/config.json\n",
      "Model config DistilBertConfig {\n",
      "  \"_name_or_path\": \"distilbert-base-uncased\",\n",
      "  \"activation\": \"gelu\",\n",
      "  \"architectures\": [\n",
      "    \"DistilBertForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.1,\n",
      "  \"dim\": 768,\n",
      "  \"dropout\": 0.1,\n",
      "  \"hidden_dim\": 3072,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"distilbert\",\n",
      "  \"n_heads\": 12,\n",
      "  \"n_layers\": 6,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"qa_dropout\": 0.1,\n",
      "  \"seq_classif_dropout\": 0.2,\n",
      "  \"sinusoidal_pos_embds\": false,\n",
      "  \"tie_weights_\": true,\n",
      "  \"transformers_version\": \"4.26.1\",\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "loading weights file pytorch_model.bin from cache at /home/peyman/.cache/huggingface/hub/models--distilbert-base-uncased/snapshots/1c4513b2eedbda136f57676a34eea67aba266e5c/pytorch_model.bin\n",
      "Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertForSequenceClassification: ['vocab_transform.weight', 'vocab_projector.weight', 'vocab_projector.bias', 'vocab_layer_norm.bias', 'vocab_transform.bias', 'vocab_layer_norm.weight']\n",
      "- This IS expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'pre_classifier.weight', 'classifier.weight', 'pre_classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "loading configuration file config.json from cache at /home/peyman/.cache/huggingface/hub/models--distilbert-base-uncased/snapshots/1c4513b2eedbda136f57676a34eea67aba266e5c/config.json\n",
      "Model config DistilBertConfig {\n",
      "  \"_name_or_path\": \"distilbert-base-uncased\",\n",
      "  \"activation\": \"gelu\",\n",
      "  \"architectures\": [\n",
      "    \"DistilBertForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.1,\n",
      "  \"dim\": 768,\n",
      "  \"dropout\": 0.1,\n",
      "  \"hidden_dim\": 3072,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"distilbert\",\n",
      "  \"n_heads\": 12,\n",
      "  \"n_layers\": 6,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"qa_dropout\": 0.1,\n",
      "  \"seq_classif_dropout\": 0.2,\n",
      "  \"sinusoidal_pos_embds\": false,\n",
      "  \"tie_weights_\": true,\n",
      "  \"transformers_version\": \"4.26.1\",\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "loading weights file pytorch_model.bin from cache at /home/peyman/.cache/huggingface/hub/models--distilbert-base-uncased/snapshots/1c4513b2eedbda136f57676a34eea67aba266e5c/pytorch_model.bin\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run 1 of None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertForSequenceClassification: ['vocab_transform.weight', 'vocab_projector.weight', 'vocab_projector.bias', 'vocab_layer_norm.bias', 'vocab_transform.bias', 'vocab_layer_norm.weight']\n",
      "- This IS expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'pre_classifier.weight', 'classifier.weight', 'pre_classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/home/peyman/anaconda3/envs/train/lib/python3.7/site-packages/transformers/optimization.py:310: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  FutureWarning,\n",
      "***** Running training *****\n",
      "  Num examples = 3660\n",
      "  Num Epochs = 3\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 1374\n",
      "  Number of trainable parameters = 66955010\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='459' max='1374' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [ 459/1374 04:53 < 09:47, 1.56 it/s, Epoch 1/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>\n",
       "    <div>\n",
       "      \n",
       "      <progress value='50' max='51' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [50/51 00:06 < 00:00, 7.35 it/s]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 407\n",
      "  Batch size = 8\n",
      "  Num examples = 407\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to ./models/bert/checkpoint-500\n",
      "Configuration saved in ./models/bert/checkpoint-500/config.json\n",
      "Model weights saved in ./models/bert/checkpoint-500/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 407\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to ./models/bert/checkpoint-1000\n",
      "Configuration saved in ./models/bert/checkpoint-1000/config.json\n",
      "Model weights saved in ./models/bert/checkpoint-1000/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 407\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to models/bert/cr_run_1_model\n",
      "Configuration saved in models/bert/cr_run_1_model/config.json\n",
      "Model weights saved in models/bert/cr_run_1_model/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 407\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='51' max='51' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [51/51 00:06]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to models/bert/cr_best_model\n",
      "Configuration saved in models/bert/cr_best_model/config.json\n",
      "Model weights saved in models/bert/cr_best_model/pytorch_model.bin\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.7069481611251831, 'eval_accuracy': 0.36117936117936117, 'eval_f1': 0.20340383026950193, 'eval_precision': 0.7733217088055798, 'eval_recall': 0.36117936117936117, 'eval_auc': 0.5083439287984742, 'eval_runtime': 7.0254, 'eval_samples_per_second': 57.933, 'eval_steps_per_second': 7.259, 'epoch': 3.0}\n"
     ]
    }
   ],
   "source": [
    "train_path  = f'data/original/cr/train.csv'\n",
    "test_path   = f'data/original/cr/test.csv'\n",
    "model_name = 'distilbert-base-uncased'\n",
    "training_args = TrainingArguments(\n",
    "    output_dir='./models/bert',\n",
    "    num_train_epochs=3,\n",
    "    per_device_train_batch_size=8,\n",
    "    per_device_eval_batch_size=8,\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    # eval_steps=100,\n",
    "    logging_steps=10,\n",
    "    # save_steps=0,\n",
    "    logging_dir='./logs/bert',\n",
    "    metric_for_best_model=\"f1\",\n",
    "    learning_rate=2e-5,\n",
    "    seed=100\n",
    "    )\n",
    "\n",
    "bert = BERT(train_path, test_path, training_args, model_name=model_name)\n",
    "# avg_dict = bert.run_n_times(name, n=3)\n",
    "# print('---------------------------------------------------')\n",
    "# print(f'Average results for {name} dataset')\n",
    "# print(avg_dict)\n",
    "# print('---------------------------------------------------')\n",
    "res = bert.train_and_evaluate(1, 'cr')\n",
    "print(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "train",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
